{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fca8cd8-67ea-49ea-ad53-f0f0676fcf9f",
   "metadata": {},
   "source": [
    "## Projekt Indywidualny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed205819-c5d2-4a22-a126-1196cc7fab40",
   "metadata": {},
   "source": [
    "Autor: <b>Daniel Ślusarczyk</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b5c04-b05b-49ef-829c-6f4f2f91cbc5",
   "metadata": {},
   "source": [
    "Opiekun projektu: <b>mgr inż. Mateusz Bartosiewicz<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186a5bd-49ca-4bdd-974d-2eb6b29e2716",
   "metadata": {},
   "source": [
    "## Spis Treści:\n",
    "1. [Cel projektu](#CP)\n",
    "2. [NLP](#NLP)\n",
    "3. [Metryki](#M)\n",
    "    1. [Powstanie metryk](#PM)\n",
    "    2. [Wady metryk](#WM)\n",
    "    3. [Zaburzanie dzialania metryk](#ZDM)\n",
    "    4. [Wpływ na postrzeganie obrazu](#WNPO)\n",
    "    5. [Translacja w Image Captioning](#TWIC)\n",
    "4. [Sposoby porównywania tesktów](#SPT)\n",
    "5. [Embeddings dla NLP](#EDN)\n",
    "6. [Zbiór COCO](#ZC)\n",
    "7. [Serwer ewauacyjny COCO](#SEC)\n",
    "8. [Źródła](#Z)\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0b6d8-96e1-4fd4-93f1-bf61331cb411",
   "metadata": {},
   "source": [
    "### Cel projektu <br> <a name=\"W\"></a>\n",
    "Nadrzędnym celem projektu jest opracowanie teoretyczne narzędzi do analizy NLP.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1520a-1777-400a-96e9-98349ba54343",
   "metadata": {},
   "source": [
    "### NLP - Przetwarzanie języka Naturalnego <a name=\"OP\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633653e0-936b-4481-b606-70cc3885a22f",
   "metadata": {
    "tags": []
   },
   "source": [
    "NLP (z ang. Natural Leanguage Processing) jest to interdyscyplinarna dziedzina, oparta na podstawach sztucznej inteligencji i językoznawstwa.\n",
    "Zajmuje się automatyzacją analizy, rozumienia, tłumaczenia i generowania języka naturalnego przez komputer.  Istnieją dwa fundamentalne kierunki przepływu informacji w NLP, które stanowią główną problematykę tej dziedziny . System, który zawiera informacje zapisane w bazie danych w sposób techniczny i zrozumiały wyłącznie dla osób zaznajomionych z sposobem zapisu przekształca się w informacje przedstawione w sposób zrozumiały dla wszystkich osób posługujących się danym językiem. Zaś system, który rozumie język naturalny modyfikuje go na formalne symbole możliwe do przetworzenia przez system komputerowy. W konsekwencji problematyka NLP dotyczy zarówno generacji i rozumienia języka.\n",
    "<br>\n",
    "<br>\n",
    "<b>Problemy stojące przed NLP:</b> \n",
    "<br>\n",
    "Ze względu na niezwykłe rozbudowanie i skomplikowanie języka naturalnego można wyróżnić wiele problemów, z którymi wiąże się dziedzina NLP:\n",
    "<ul>\n",
    "<li> Segmentacja sygnału mowy</li>\n",
    "<li> Segmentacja tekstu</li>\n",
    "<li> Wieloznaczność słów</li>\n",
    "<li> Syntaktyczna niejednoznaczność</li>\n",
    "<li> Nieprawidłowe, bądź nieregularne dane</li>\n",
    "<li> Akt mowy i plan</li>\n",
    "</ul>\n",
    "<b> Przykładowe zadania NLP:</b>\n",
    "<ul>\n",
    "<li> Automatyczna sumaryzacja – program umożliwiający streszczenie dłuższego tekstu w krótszy o tym samym przesłaniu i najważniejszych informacjach</li>\n",
    "<li> Synteza mowy – operacja polegająca na przetwarzaniu języka na mowę</li>\n",
    "<li> Korekcja tekstu – analiza tekstu i wykrywanie błędów</li>\n",
    "<li> Rozpoznawanie mowy – operacja polegająca na przetwarzaniu mowy na tekst </li>\n",
    "</ul>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006d249-29de-44e7-bd07-b5f404a225e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metryki "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2d274-6a4b-4e26-8c92-a05d7e0af6e0",
   "metadata": {},
   "source": [
    "Metryki są nieodłączonym elementem uczenia maszynowego. Służa do oceny spełnienia oczekiwań stawianych przed problemem, do którego używana jest dana metryka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8d204-3929-44ac-a886-7856f8ab5975",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51175e7d-4bba-4167-a56b-0d8d7c6368e4",
   "metadata": {},
   "source": [
    "<b><font color='red'>B</font>i<font color='red'>L</font>ingual <font color='red'>E</font>valuation <font color='red'>U</font>nderstudy</b>\n",
    "<br>\n",
    "Ewaluacja służąca do mierzenia jakości modeli tłumaczenia maszynowego. Zadaniem tej metryki jest ocena jak dobrze model tłumaczy tekst pomiędzy językami. W przypadku tej metryki \"jakość\" rozumiana jest jako korelacja pomiędzy danymi wyjściowymi a tekstem ludzkim - im tłumaczenie bardziej zbliżone do tłumaczenia ludzkiego, tym jest uzawane za lepsze. BLEU jest jedną z pierwszych metryk, której udało się uzyskać wyniki zbliżone z ludzkim osądem. W konsekwencji stała się najbardziej popularną metodą, pomimo pewnych wad.\n",
    "\n",
    "<b>Działanie:</b><br>\n",
    "Założeniem BLEU jest ocena dużych korposów. Nie znajduje zastosowania do oceny pojedynczych zdań. Algorytm porównuje n-gram tłumaczenia kandydata z n-gramem tłumaczenie wzorcowego w celu policzenia liczby wystąpień (miejsce wystąpienia nie ma znaczenia). Im większa liczba wystąpień n-gramu pomiędzy kandydatem i wzorcem tym tłumaczenie jest uznawane za lepsze. Wynikiem tej metryki jest liczba z zakresu 0-1. Metryka BLEU uwzględnia również różnice w długości pomiędzy tłumaczeniem wzorcowym, a kandydowanym za pomocą współczynnika BP.<br>\n",
    "Dla c > r lub c = r:\n",
    "$$\n",
    "  BP = 1 \n",
    "$$\n",
    "Dla c < r:\n",
    "$$\n",
    "  BP = e^{1-\\frac{r}{c}}\n",
    "$$\n",
    "r - liczba słów w wzorcowym tłumaczeniu<br>\n",
    "c - liczba słów w kandydowanym tłumaczeniu<br>\n",
    "\n",
    "Końcowa wartość metryki jest równa:\n",
    "$$\n",
    "  BLUE = BP * exp( \\sum \\limits_{n=1} ^{N} w_{n} log (p_{n}))\n",
    "$$\n",
    "N - liczba rozważanym n-gramów<br>\n",
    "wn - waga danego n-gramu<br>\n",
    "pn - stosunek wystąpień danego n-gramu do wszystkich n-gramów<br>\n",
    "<br>\n",
    "Problemy metryki:\n",
    "* Udowodniono, że wzrost wartości BLEU nie musi mieć przełożenia na wzrost jakości tłumaczenia\n",
    "* Istnieją przypadki, że wyniki BLEU znacząco odbiegają od ludzkiej oceny\n",
    "* W przypadku użycia metryki BLEU do porównywania dwóch systemów oba systemy powinny być podobne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d791e-962b-4e0f-a5ea-fc018e3cf720",
   "metadata": {},
   "source": [
    "Import potrzebnych pakietów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef6121-c0e2-4a3a-ab0b-45a05740add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorcowa wartość BLEU:\n",
    "import nltk.translate.bleu_score as bleu\n",
    "# Wyrażenia regularne do wyszukiwania słów w tekście:\n",
    "import re\n",
    "# Obliczenia:\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f755473-d072-4e18-8e21-5cc74980f361",
   "metadata": {},
   "source": [
    "Analizowane dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b586094b-c7d7-4602-8ef6-8429fdc2e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagi przypisane do poszczególnych n-gramów:\n",
    "# [Uwaga] Przypisanie 0 do wagi oznacza wykluczenie danego n-gramu z analizy\n",
    "weights = (0.25, 0.25)\n",
    "\n",
    "# Tłumaczenia referencyjne\n",
    "references = [\n",
    "            'It is guide to action that ensures that the miliatry will forever heed Party commands'.split(), \n",
    "            'It is the guide principle which guarantees the miliatry forces always being under the command of the Party'.split()\n",
    "            ]\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'It is a guide to action which ensures that the miliatry always obeys the commands of the party'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190f9c5-60d4-424f-a2e8-401a38720ebd",
   "metadata": {},
   "source": [
    "Potwierdzenie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3039a319-5307-46c1-ae14-c6ac32c928ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba rozpatrywanych n-gramów:                   2\n",
      "Liczba tłumaczeń referencyjnych (wzorcowych):     2\n",
      "Maksymalna długość kandydata:                     18\n",
      "Tłumaczenie kandydujące:                          ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
      "Tłumaczenie kandydujące bez powtórzeń:            ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'commands', 'of', 'party']\n"
     ]
    }
   ],
   "source": [
    "# Ilość analizowanych n-gramów\n",
    "n = getNumberOfnGram(weights)\n",
    "print(\"{0:<50}\".format(\"Liczba rozpatrywanych n-gramów: \") + str(n))\n",
    "\n",
    "# Liczba referencji\n",
    "refNmb = len(references)\n",
    "print(\"{0:<50}\".format(\"Liczba tłumaczeń referencyjnych (wzorcowych): \") + str(refNmb))\n",
    "\n",
    "# Maksymalna długość kandydata/wzorca\n",
    "max_size = getMaxLengthOflist(references)\n",
    "print(\"{0:<50}\".format(\"Maksymalna długość kandydata: \") + str(max_size))\n",
    "\n",
    "# Unikalne słowa kandydata \n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące: \") + str(candidate))\n",
    "unique_candidate = makeUniqueList(candidate)\n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące bez powtórzeń: \") + str(unique_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b24118-4fde-4d08-bb2a-4a7f982db6be",
   "metadata": {},
   "source": [
    "Obliczenie wzorcowego BLEU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c693ef0f-22d8-4540-883b-2ad999808367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wzorcowe BLEU Score:  0.7653621274462215\n"
     ]
    }
   ],
   "source": [
    "print(\"Wzorcowe BLEU Score: \", bleu.sentence_bleu(references, candidate, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eee380-2e5c-432a-bf23-c57b80f41769",
   "metadata": {},
   "source": [
    "Funkcje pomocnicze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49e27cc8-0053-4a88-92b8-9b1de798c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiuje liczbę rozpatrywanych n-gramów zależnie od przypisanych wag\n",
    "def getNumberOfnGram(weights):\n",
    "    n = len(weights)\n",
    "    result = 0\n",
    "    for i in range(1, n):\n",
    "        if( weights[i - 1] == 0 ):\n",
    "            break\n",
    "        else:\n",
    "            result = i\n",
    "    return result + 1\n",
    "\n",
    "# Zwraca liczbę wystąpień pattern w text - wyrażenia regularne\n",
    "def getNumberOfOccurance(pattern, text):\n",
    "    # \"pattern\"\n",
    "    number = re.findall(\"^\" + pattern + \"$\", text)\n",
    "    # \"pattern \"\n",
    "    number = number + re.findall(\"^\" + pattern + \" \", text)\n",
    "    # \" pattern \"\n",
    "    number = number + re.findall(\" \" + pattern + \" \", text)\n",
    "    # \" pattern\"\n",
    "    number = number + re.findall(\" \" + pattern + \"$\", text)\n",
    "    return len(number)\n",
    "\n",
    "# Tworzy z inputList listę bez duplikatów\n",
    "def makeUniqueList(inputList):\n",
    "    unique_list = []\n",
    "    for element in inputList:\n",
    "        if element not in unique_list:\n",
    "            unique_list.append(element)\n",
    "    return unique_list\n",
    "\n",
    "# Zwraca z długość najdłuższej listy z listy\n",
    "def getMaxLengthOflist(inputList):\n",
    "    size = len (candidate)\n",
    "    for element in inputList:\n",
    "        if(size < len(element)):\n",
    "            size = len(element)\n",
    "    return size\n",
    "\n",
    "# Oblicz karę za niedopasowanie długości\n",
    "def lengthPenalty(refLength, canLength):\n",
    "    result = math.exp(1-refLength/canLength)\n",
    "    return result\n",
    "\n",
    "# Oblicz końcową wartość wyniku i wyświetla na ekran\n",
    "def calculateResult(listOfResults, listOfNmbOfGrams, bp):\n",
    "    if(len(listOfResults) == len (listOfNmbOfGrams)):\n",
    "        sumOfLog = 0\n",
    "        print(\"\\nBLUE = \" + \"{:.3f}\".format(bp) + \" exp( \", end ='')\n",
    "        \n",
    "        for con in range(0, len(listOfResults)):\n",
    "            print( \" ln( \" + str(listOfResults[con]) + \"/\" + str(listOfNmbOfGrams[con]) + \" )\",end='')\n",
    "            if(con != len(listOfResults) - 1):\n",
    "                print(\" +\", end = '')\n",
    "                \n",
    "            sumOfLog = sumOfLog + weights[con] * math.log(listOfResults[con]/listOfNmbOfGrams[con])\n",
    "        print(\" ) = \" + str(bp * math.exp(sumOfLog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d9812-d547-4572-8ccf-7f55c213e174",
   "metadata": {},
   "source": [
    "Główna funkcja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8098dd8e-e140-47a5-b4a0-8b02a2620051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-GRAM\t\t\t\t\t\t\tRef1\tRef2\tMax Ref Count\tClip Count\tContribution\n",
      "1)It                          \t\t\t\t1\t1\t1\t1\t1\n",
      "2)is                          \t\t\t\t1\t1\t1\t1\t1\n",
      "3)a                           \t\t\t\t0\t0\t0\t1\t0\n",
      "4)guide                       \t\t\t\t1\t1\t1\t1\t1\n",
      "5)to                          \t\t\t\t1\t0\t1\t1\t1\n",
      "6)action                      \t\t\t\t1\t0\t1\t1\t1\n",
      "7)which                       \t\t\t\t0\t1\t1\t1\t1\n",
      "8)ensures                     \t\t\t\t1\t0\t1\t1\t1\n",
      "9)that                        \t\t\t\t2\t0\t2\t1\t1\n",
      "10)the                        \t\t\t\t1\t4\t4\t3\t3\n",
      "11)miliatry                   \t\t\t\t1\t1\t1\t1\t1\n",
      "12)always                     \t\t\t\t0\t1\t1\t1\t1\n",
      "13)obeys                      \t\t\t\t0\t0\t0\t1\t0\n",
      "14)commands                   \t\t\t\t1\t0\t1\t1\t1\n",
      "15)of                         \t\t\t\t0\t1\t1\t1\t1\n",
      "16)party                      \t\t\t\t0\t0\t0\t1\t0\t\t15\\16\n",
      "\n",
      "17)It is                      \t\t\t\t1\t1\t1\t1\t1\n",
      "18)is a                       \t\t\t\t0\t0\t0\t1\t0\n",
      "19)a guide                    \t\t\t\t0\t0\t0\t1\t0\n",
      "20)guide to                   \t\t\t\t1\t0\t1\t1\t1\n",
      "21)to action                  \t\t\t\t1\t0\t1\t1\t1\n",
      "22)action which               \t\t\t\t0\t0\t0\t1\t0\n",
      "23)which ensures              \t\t\t\t0\t0\t0\t1\t0\n",
      "24)ensures that               \t\t\t\t1\t0\t1\t1\t1\n",
      "25)that the                   \t\t\t\t1\t0\t1\t1\t1\n",
      "26)the miliatry               \t\t\t\t1\t1\t1\t1\t1\n",
      "27)miliatry always            \t\t\t\t0\t0\t0\t1\t0\n",
      "28)always obeys               \t\t\t\t0\t0\t0\t1\t0\n",
      "29)obeys the                  \t\t\t\t0\t0\t0\t1\t0\n",
      "30)the commands               \t\t\t\t0\t0\t0\t1\t0\n",
      "31)commands of                \t\t\t\t0\t0\t0\t1\t0\n",
      "32)of the                     \t\t\t\t0\t1\t1\t1\t1\n",
      "33)the party                  \t\t\t\t0\t0\t0\t1\t0\t\t7\\17\n",
      "\n",
      "\n",
      "Długość tłumaczenia wzorcowego: 18\n",
      "Długość tłumaczenia kandydującego: 18\n",
      "BP: 1.0\n",
      "\n",
      "BLUE = 1.000 exp(  ln( 15/16 ) + ln( 7/17 ) ) = 0.7882338816522895\n"
     ]
    }
   ],
   "source": [
    "# Zmienne pomocnicze\n",
    "counter = 1\n",
    "tabs = '\\t\\t\\t\\t'\n",
    "listOfnmbOfGrams = []\n",
    "listOfResult = []\n",
    "\n",
    "print(\"n-GRAM\" + tabs + \"\\t\\t\\tRef1\" + \"\\tRef2\" + \"\\tMax Ref Count\" + \"\\tClip Count\" + \"\\tContribution\")\n",
    "# Pętla po liczbie n (liczbie rozpatrywanych n-gramów)\n",
    "for ngram in range(1, n + 1):\n",
    "    \n",
    "    # Suma wszystkich clipCount jednego n-gramu\n",
    "    sumClipCount = 0\n",
    "    # Liczba n-gramów:\n",
    "    if(ngram > 1):\n",
    "        unique_candidate = candidate\n",
    "    nmbOfGrams = len(unique_candidate) - ngram + 1\n",
    "    \n",
    "    # Pętla po liczbie n-gramów zależna od rozpatrywanego n-gramu\n",
    "    for idOfPattern in range(0, nmbOfGrams):\n",
    "        \n",
    "        gram = unique_candidate[idOfPattern]\n",
    "        # Pętla po liczbie słów do dodania aby otrzymać n-gram\n",
    "        for idToAdd in range(1, ngram):\n",
    "            gram = gram + ' ' + unique_candidate[idOfPattern + idToAdd]\n",
    "        \n",
    "        #Wypisanie początku wiersza tabeli\n",
    "        print(\"{0:<30}\".format(str(counter) + \")\" + gram), end='')\n",
    "        print(tabs, end='')\n",
    "        \n",
    "        #Zmienne dla konkretnego n-gramu:\n",
    "        counter = counter + 1\n",
    "        maxRefCount = 0\n",
    "        count = 0\n",
    "        candidateWithoSpace = ' '.join(map(str, candidate))\n",
    "        count = getNumberOfOccurance(gram, candidateWithoSpace)\n",
    "        \n",
    "        # Sprawdzanie wystąpień n-gramu w referencjach\n",
    "        for reference in references:\n",
    "            referenceWithSpace = ' '.join(map(str, reference))\n",
    "            # Sprawdzenie wystąpienia konkretnego n-gramu w danej referencji\n",
    "            if(gram in referenceWithSpace):\n",
    "                gramOccurrances = getNumberOfOccurance(gram, referenceWithSpace)\n",
    "                print(str(gramOccurrances) + '\\t', end='')\n",
    "                maxRefCount = max(maxRefCount, gramOccurrances)\n",
    "            else:\n",
    "                print(\"0\" + '\\t', end='')\n",
    "        \n",
    "        # Obliczanie wartości sumClipCount\n",
    "        sumClipCount = sumClipCount + min(maxRefCount, count)\n",
    "        \n",
    "        #Wypisywanie maxRefCount i Coun\n",
    "        if(idOfPattern != nmbOfGrams - 1):\n",
    "            print(str(maxRefCount) + '\\t' + str(count) + '\\t' + str(min(maxRefCount, count)))\n",
    "        else:\n",
    "            print(str(maxRefCount) + '\\t' + str(count) + '\\t' + str(min(maxRefCount, count)), end ='')\n",
    "    \n",
    "    #Zapisanie wkładu danego n-gramu do oceny\n",
    "    listOfnmbOfGrams.append(nmbOfGrams)\n",
    "    listOfResult.append(sumClipCount)\n",
    "    print(\"\\t\\t\" + str(sumClipCount) + \"\\\\\" + str(nmbOfGrams) + \"\\n\")\n",
    "\n",
    "\n",
    "# Kara stratności:\n",
    "refLength = max_size\n",
    "print(\"\\nDługość tłumaczenia wzorcowego: \" + str(refLength))\n",
    "canLength = len(candidate)\n",
    "print(\"Długość tłumaczenia kandydującego: \" + str(canLength))\n",
    "bp = lengthPenalty(refLength, canLength)\n",
    "\n",
    "print(\"BP: \" + str(bp))\n",
    "calculateResult(listOfResult, listOfnmbOfGrams, bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc74cfd-9c7c-4126-a8bf-3383c31b2ee9",
   "metadata": {},
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012cdad-05c4-4fdf-a185-5523e0fd63b5",
   "metadata": {},
   "source": [
    "**Metric for Evaluation of Translation with Explicit ORdering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bddbba-a9be-4ee5-873e-5d566fd4aedb",
   "metadata": {},
   "source": [
    "Metryka używana do oceny tłumaczenia maszynowego. Operta na średniej harmonicznej n-gramów precyzji i pokrycia z przyznaniem większej wagi dla pokrycia. Cechą charakterystyczną tej metryki jest dopasowywanie synonimów - akceptowanie wyrazów o podobnym znaczeniu. Powodem powstania tej metryki jest próba wyeliminowania błędów pojawiających się w metryce BLEU. Główna różnicą pomiędzy tymi metrykami jest poziom szukania korelacji. BLUE skupia się na poziomie całego korpusy, natomiast METEOR na poziomie zdań i segmentów.\n",
    "<br><br>\n",
    "**Działanie:**\n",
    "METEOR w celu oszacowania jakości tłumaczenia maszynowego porównuje je z jednym/dwoma tłumaczeniami wzorcowymi. Wynik ewaluacji jest obliczany osobno dla każdego zdania w taki sposób, że każde zdanie z tłumaczenia maszynowego jest porównywane ze zdaniem z tłumaczenia wzorcowego, a następnie do dalszej analizy brana jest pod uwagę lepsza ocena. Metryka METEOR posługuje się dwoma modułami:\n",
    "* Etap pierwszy: METEOR ALIGNER - tworzenie odwzorowania pomiędzymi tłumaczeniami\n",
    "* Etap drugi: METEOR SCORER - obliczanie końcowego wyniku\n",
    "\n",
    "Etap pierwszy:<br>\n",
    "Etap pierwszy dzieli się na dwa zasadniczne kroki: zidentyfikowanie wszystkich odwzorowań pomiędzy tłumaczeniem ocenianym a wzorcowym i wyselekcjonowanie najlepszego odwzorowania. <br>\n",
    "\n",
    "Identyfikacja odwzorowań: <br>\n",
    "Odwzorowanień w metryce METEOR jest lista słów z tłumaczenia wzorcowego, które w jakiś spoób odpowiadają słowu z tłumaczenia maszynowego. Proces dopasowywania jest realizowany poprzez cztery moduły:\n",
    "* exact - dopasowanie słów identycznych\n",
    "* stem - dopasowanie słów o identycznym rdzeniu\n",
    "* synonym - dopasowanie słów bliskoznacznych według bazy WorldNet\n",
    "* paraphrase - dopasowanie fraz wymienionych jako parafrazy w tabeli parafrazowej\n",
    "\n",
    "Przykład: <br>\n",
    "Tłumaczenie maszynowe (T): Chłopak bajkę opowiadał bez ogródek <br>\n",
    "Tłumaczenie wzorcowe (T): Chłopczyk opowiada historię bez owijania w bawełnę <br>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"METEOR_schemat.png\"/>\n",
    "</p>\n",
    "\n",
    "Wyselekcjonowanie najlepszego odwzorowania:\n",
    "Krok ten polega na znalezieniu największego podzbioru dopasowań wśród dopasowań znalezionych w pierwszym etapie i spełniających kryteria:\n",
    "* Każde słowo może należeć tylko do jednego dopasowania\n",
    "* Dopasowywana jest możliwie największa liczba słów w obu tłumaczeniach\n",
    "* W wyniku wybranych dopasowań występuje możliwie najmniejsza liczba fraz przylegających do siebie i występujących w tej samej kolejności w obu tłumaczeniach\n",
    "* Pomiędzy pozycjami startowymi dopasowań wystąpi jak najmniejsza suma odstępów - faworyzowanie dopasowań na podobnych pozycjach w obu tłumaczeniach\n",
    "\n",
    "Najlepsze dopasowanie:\n",
    "<p align=\"center\">\n",
    "  <img src=\"METEOR_schemat2.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd4250-886e-4e36-b826-8fa274c13c71",
   "metadata": {},
   "source": [
    "Etap drugi:<br>\n",
    "Celem etapu drugiego jest obliczenie wyniku końcowego metryki na podstawie wyniku pierwszego etapu. Końcowy wynik oparty jest na kilku wartościach:\n",
    "* Precyzja<br>\n",
    "Stosunek dopasowań wyrazów w ocenianym tłumaczeniu do wszystkich wyrazów tłumaczenia.\n",
    "$$\n",
    "  P = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(t)}{|t|}\n",
    "$$\n",
    "n - liczba modułów biorących udział w dopasowaniu<br>\n",
    "wi - waga i-tego modułu<br>\n",
    "mi(t) - liczb wyrazów dopasowanych przez i-ty moduł<br>\n",
    "|t| - liczba wszystkich wyrazów w tłumaczeniu<br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(t) + w_{stem} * m_{stem}(t) + w_{synonym} * m_{synonym}(t) + w_{paraphrase} * m_{paraphrase}(t) }{6}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$\n",
    "* Pokrycie <br>\n",
    "Stosunek wyrazów w tłumaczeniu wzorcowym, które zostały dopasowane w tłumaczeniu maszynowym do wszystkich wyrazów tłumaczenia wzorcowego.\n",
    "$$\n",
    "  R = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(r)}{|r|}\n",
    "$$\n",
    "mi(r) - liczba wyrazów dopasowanych w tłumaczeniu referencyjnym<br>\n",
    "|r| - liczba wyrazów tłumaczenia wzorcowego <br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(r) + w_{stem} * m_{stem}(r) + w_{synonym} * m_{synonym}(r) + w_{paraphrase} * m_{paraphrase}(r) }{6}\n",
    "$$\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff8acf-a6b6-4314-a1ba-ab6962438672",
   "metadata": {},
   "source": [
    "BLEU:\n",
    "* https://towardsdatascience.com/bleu-bilingual-evaluation-understudy-2b4eab9bcfd1\n",
    "BLEU i METEOR:\n",
    "* http://docplayer.pl/14218168-Ewaluacja-systemow-tlumaczenia-automatycznego.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755c315-d803-4143-bf6a-584967d58740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
