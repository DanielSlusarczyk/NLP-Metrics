{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fca8cd8-67ea-49ea-ad53-f0f0676fcf9f",
   "metadata": {},
   "source": [
    "## Projekt Indywidualny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed205819-c5d2-4a22-a126-1196cc7fab40",
   "metadata": {},
   "source": [
    "Autor: <b>Daniel Ślusarczyk</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b5c04-b05b-49ef-829c-6f4f2f91cbc5",
   "metadata": {},
   "source": [
    "Opiekun projektu: <b>mgr inż. Mateusz Bartosiewicz<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186a5bd-49ca-4bdd-974d-2eb6b29e2716",
   "metadata": {},
   "source": [
    "## Spis Treści:\n",
    "1. [Cel projektu](#CP)\n",
    "2. [NLP](#NLP)\n",
    "3. [Metryki](#M)\n",
    "    1. [BLEU](#BLEU)\n",
    "        1. [Opis](#BLEU_O)\n",
    "        2. [Działanie](#BLEU_D)\n",
    "        3. [Problemy](#BLEU_P)\n",
    "    2. [METOR](#METEOR)\n",
    "        1. [Opis](#BLEU_O)\n",
    "        2. [Działanie](#BLEU_D)\n",
    "        3. [Problemy](#BLEU_P)\n",
    "4. [Sposoby porównywania tesktów](#SPT)\n",
    "5. [Embeddings dla NLP](#EDN)\n",
    "6. [Zbiór COCO](#ZC)\n",
    "7. [Serwer ewauacyjny COCO](#SEC)\n",
    "8. [Źródła](#Z)\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0b6d8-96e1-4fd4-93f1-bf61331cb411",
   "metadata": {},
   "source": [
    "### Cel projektu <br> \n",
    "<a name=\"CP\"></a>\n",
    "Celem projektu jest opracowanie teoretyczne narzędzi do analizy NLP.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1520a-1777-400a-96e9-98349ba54343",
   "metadata": {},
   "source": [
    "### NLP - Przetwarzanie Języka Naturalnego\n",
    "<a id =\"NLP\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633653e0-936b-4481-b606-70cc3885a22f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "NLP (z ang. Natural Leanguage Processing) jest to interdyscyplinarna dziedzina, oparta na podstawach sztucznej inteligencji i językoznawstwa.\n",
    "Zajmuje się automatyzacją analizy, rozumienia, tłumaczenia i generowania języka naturalnego przez komputer.  Istnieją dwa fundamentalne kierunki przepływu informacji w NLP, które stanowią główną problematykę tej dziedziny . System, który zawiera informacje zapisane w bazie danych w sposób techniczny i zrozumiały wyłącznie dla osób zaznajomionych z sposobem zapisu przekształca się w informacje przedstawione w sposób zrozumiały dla wszystkich osób posługujących się danym językiem. Zaś system, który rozumie język naturalny modyfikuje go na formalne symbole możliwe do przetworzenia przez system komputerowy. W konsekwencji problematyka NLP dotyczy zarówno generacji i rozumienia języka.\n",
    "</p>\n",
    "<br>\n",
    "<b>Problemy stojące przed NLP:</b> \n",
    "<br>\n",
    "Ze względu na niezwykłe rozbudowanie i skomplikowanie języka naturalnego można wyróżnić wiele problemów, z którymi wiąże się dziedzina NLP:\n",
    "<ul>\n",
    "<li> Segmentacja sygnału mowy</li>\n",
    "<li> Segmentacja tekstu</li>\n",
    "<li> Wieloznaczność słów</li>\n",
    "<li> Syntaktyczna niejednoznaczność</li>\n",
    "<li> Nieprawidłowe, bądź nieregularne dane</li>\n",
    "<li> Akt mowy i plan</li>\n",
    "</ul>\n",
    "<b> Przykładowe zadania NLP:</b>\n",
    "<ul>\n",
    "<li> Automatyczna sumaryzacja – program umożliwiający streszczenie dłuższego tekstu w krótszy o tym samym przesłaniu i najważniejszych informacjach</li>\n",
    "<li> Synteza mowy – operacja polegająca na przetwarzaniu języka na mowę</li>\n",
    "<li> Korekcja tekstu – analiza tekstu i wykrywanie błędów</li>\n",
    "<li> Rozpoznawanie mowy – operacja polegająca na przetwarzaniu mowy na tekst </li>\n",
    "</ul>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006d249-29de-44e7-bd07-b5f404a225e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metryki \n",
    "<a class=\"anchor\" id =\"M\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2d274-6a4b-4e26-8c92-a05d7e0af6e0",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Wzmożony rozwój NLP skutkuje zwiększoną potrzebą oceny jakosci powstających systemów automatycznego przetwarzania języka naturalnego. Metryki są nieodłączonym elementem uczenia maszynowego. Służa do oceny spełnienia oczekiwań stawianych przed rozwiązaniem problememu, do którego używany jest ewaluowany system.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8d204-3929-44ac-a886-7856f8ab5975",
   "metadata": {},
   "source": [
    "### BLEU\n",
    "<a class=\"anchor\" id =\"BLEU\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51175e7d-4bba-4167-a56b-0d8d7c6368e4",
   "metadata": {},
   "source": [
    "<b><font color='red'>B</font>i<font color='red'>L</font>ingual <font color='red'>E</font>valuation <font color='red'>U</font>nderstudy</b>\n",
    "<a class=\"anchor\" id =\"BLEU_O\"></a>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "Ewaluacja służąca do mierzenia jakości modeli tłumaczenia maszynowego kierująca się zasadą \"im bliższe tłumaczenie automatyczne i profesjonalne ludzkie tłumaczenie, tym lepiej\". Zadaniem tej metryki jest ocena jak dobrze model tłumaczy tekst pomiędzy językami. W przypadku tej metryki \"jakość\" rozumiana jest jako korelacja pomiędzy danymi wyjściowymi a tekstem ludzkim. Został przedstawiony w 2002 roku i opisany w raporcie firmy IBM. BLEU jest jedną z pierwszych metryk, której udało się uzyskać wyniki zbliżone z ludzkim osądem. W konsekwencji stała się najbardziej popularną metodą, pomimo pewnych wad.\n",
    "</p>\n",
    "\n",
    "<b>Działanie</b><br>\n",
    "<a class=\"anchor\" id =\"BLEU_D\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "Działanie metryki zostanie przedstawione na podstawie kodu, który krok po kroku przeprowadza potrzebne operacje w celu obliczenia wartości metryki. Prezentowany kod ma charakter prezentacyjny i wizualizuje wiele informacji w celu łatwiejszego zrozumienia działania metryki. Wynik uzyskany przez kod jest możliwy do porównania ze wzorcowym wynikiem.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d791e-962b-4e0f-a5ea-fc018e3cf720",
   "metadata": {},
   "source": [
    "Import potrzebnych pakietów: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Pakiet \"nltk.translate.bleu_score\" importowany jako alias \"bleu\" służy do uzyskania wzorcowego wyniku na końcu przykładu w celu porównania go z wynikiem uzyskanym przez\n",
    "kod. Pakiety \"re\" i \"math\" są używane do przeprowadzenia operacji, których wymaga sposób obliczania metryki BLEU.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eef6121-c0e2-4a3a-ab0b-45a05740add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorcowa wartość BLEU:\n",
    "import nltk.translate.bleu_score as bleu\n",
    "# Wyrażenia regularne do wyszukiwania słów w tekście:\n",
    "import re\n",
    "# Obliczenia:\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f755473-d072-4e18-8e21-5cc74980f361",
   "metadata": {},
   "source": [
    "Analizowane dane: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Metryka BLEU opiera działanie na porównywaniu n-gramów tłumaczenia kandydata z n-gramami tłumaczeń wzorcowych (miejsce wystąpienia analizowanego n-gramu w tłumaczeniu kandydatującym i wzorcu nie ma znaczenia). Im większa liczba wspólnych n-gramów pomiędzy kandydatem i wzorcem tym tłumaczenie jest uznawane za lepsze. Metryka BLEU pozwala na dostosowanie wag poszczególnych n-gramów i przypisanie większej wartości n-gramom, które powinny być szczególnie uwzględniane. Wartość listy <b>weights</b> służy do podania wag dla poszczególnych n-gramów. Podanie wartości 0 jest jednoznaczne z wyzerowaniem wpływu danego n-gramu na wynik końcowy. Niepodanie żadnej wartości pozwala całkowicie wykluczyć ostatnie n-gramy z analizy. Lista <b>references</b> służy do podania wzorcowych tłumaczeń dla danego tłumaczenia kandydującego <b>candidate</b>. Sposób prawidłowego wpisania tych danych jest przedstawiony poniżej.<br>\n",
    "</p>\n",
    "Przykłady: <br>\n",
    "weights = (0.25) - uwzględnienie w obliczeniach jedynie unigramów <br>\n",
    "weights = (0, 0, 0.25) - uwzględnienie w wyniku jedynie trigramów. Przeprowadzenie analizy dla unigramów, bigramów i trigramów <br>\n",
    "weights = (0.2, 0.3, 0.4, 0.5) - uwzględnienie w obliczeniach od unigramu do 4-gramu z przypisaniem kolejno wag: 0.2, 0.3, 0.4, 0.5 <br>\n",
    "references = ['Recepcjonista poinformował o zamknięciu hotelu'.split(), 'Pracownik recepcji poinformował o zamknięciu hotelu'.split()] - zdefiniowanie dwóch tłumaczeń wzorcowych dla tłumaczenia kandydującego <br>\n",
    "references = ['Recepcjonista poinformował o zamknięciu hotelu'.split()] - zdefiniowanie jednego tłumaczenia wzorcowego dla tłumaczenia kandydującego <br>\n",
    "candidate = 'Pan pracujący na recepecji udzielił informacji o zamknięciu hotelu'.split() - zdefiniowanie ocenianego tłumaczenia (kandydata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b586094b-c7d7-4602-8ef6-8429fdc2e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagi przypisane do poszczególnych n-gramów:\n",
    "weights = [0.25, 0.25, 0.25]\n",
    "\n",
    "# Tłumaczenia referencyjne\n",
    "references = [\n",
    "            'It is guide to action that ensures that the miliatry will forever heed Party commands'.split(), \n",
    "            'It is the guide principle which guarantees the miliatry forces always being under the command of the Party'.split(),\n",
    "            'It is the practical guide for the army always to heed the directions of the party'.split()\n",
    "            ]\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'It is a guide to action which ensures that the miliatry always obeys the commands of the party'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca0f31-21d5-4a04-ad7e-4dc908999ca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Funkcje pomocnicze: <br>\n",
    "Kod korzysta z poniższych zdefiniowanych funkcji, które pozwalają na łatwiejszego zrozumienie kodu. Zrozumienie ich działania nie jest konieczne do zrozumienia działania metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f06d16e-337d-48be-9e36-1bcf9be7e458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wyświetla informacje o tabeli\n",
    "def describeTable(nRef):\n",
    "    counter = 1\n",
    "    print(\"n-GRAM\" + tabs + \"\\t\\t\\tRef1\", end='')\n",
    "    for ref in range(1, nRef):\n",
    "        counter = counter + 1\n",
    "        print(\"\\tRef\" + str(counter), end='')\n",
    "\n",
    "    print(\"\\tMax Ref Count\" + \"\\tClip Count\" + \"\\tContribution\")\n",
    "\n",
    "# Definiuje liczbę rozpatrywanych n-gramów zależnie od przypisanych wag\n",
    "def getNumberOfnGram(weights):\n",
    "    n = len(weights)\n",
    "    result = 0\n",
    "    for i in range(1, n):\n",
    "        if( weights[i - 1] == 0 ):\n",
    "            break\n",
    "        else:\n",
    "            result = i\n",
    "    return result + 1\n",
    "\n",
    "# Zwraca liczbę wystąpień pattern w text - wyrażenia regularne\n",
    "def getNumberOfOccurance(pattern, text):\n",
    "    # \"pattern\"\n",
    "    number = re.findall(\"^\" + pattern + \"$\", text)\n",
    "    # \"pattern \"\n",
    "    number = number + re.findall(\"^\" + pattern + \" \", text)\n",
    "    # \" pattern \"\n",
    "    number = number + re.findall(\" \" + pattern + \" \", text)\n",
    "    # \" pattern\"\n",
    "    number = number + re.findall(\" \" + pattern + \"$\", text)\n",
    "    return len(number)\n",
    "\n",
    "# Tworzy z inputList listę bez duplikatów\n",
    "def makeUniqueList(inputList):\n",
    "    unique_list = []\n",
    "    for element in inputList:\n",
    "        if element not in unique_list:\n",
    "            unique_list.append(element)\n",
    "    return unique_list\n",
    "\n",
    "# Zwraca z długość najdłuższej listy z listy\n",
    "def getMaxLengthOflist(inputList):\n",
    "    size = len (candidate)\n",
    "    for element in inputList:\n",
    "        if(size < len(element)):\n",
    "            size = len(element)\n",
    "    return size\n",
    "\n",
    "# Oblicz karę za niedopasowanie długości\n",
    "def lengthPenalty(refLength, canLength):\n",
    "    result = math.exp(1-refLength/canLength)\n",
    "    return result\n",
    "\n",
    "# Oblicz końcową wartość wyniku i wyświetla\n",
    "def calculateResult(listOfResults, listOfNmbOfGrams, bp):\n",
    "    if(len(listOfResults) == len (listOfNmbOfGrams)):\n",
    "        sumOfLog = 0\n",
    "        print(\"\\nBLUE = \" + \"{:.3f}\".format(bp) + \" exp( \", end ='')\n",
    "        \n",
    "        for con in range(0, len(listOfResults)):\n",
    "            print( \" ln( \" + str(listOfResults[con]) + \"/\" + str(listOfNmbOfGrams[con]) + \" )\",end='')\n",
    "            if(con != len(listOfResults) - 1):\n",
    "                print(\" +\", end = '')\n",
    "                \n",
    "            sumOfLog = sumOfLog + weights[con] * math.log(listOfResults[con]/listOfNmbOfGrams[con])\n",
    "        print(\" ) = \" + str(bp * math.exp(sumOfLog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190f9c5-60d4-424f-a2e8-401a38720ebd",
   "metadata": {},
   "source": [
    "Potwierdzenie danych: <br>\n",
    "Wykonanie poniższego kodu pozwala na potwierdzenie poprawności wprowadzonych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3039a319-5307-46c1-ae14-c6ac32c928ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba rozpatrywanych n-gramów:                   3\n",
      "Liczba tłumaczeń referencyjnych (wzorcowych):     3\n",
      "Maksymalna długość wzorca:                        18\n",
      "Maksymalna długość kandydata:                     18\n",
      "Tłumaczenie kandydujące:                          ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
      "Tłumaczenie kandydujące bez powtórzeń:            ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'commands', 'of', 'party']\n"
     ]
    }
   ],
   "source": [
    "# Ilość analizowanych n-gramów\n",
    "n = getNumberOfnGram(weights)\n",
    "print(\"{0:<50}\".format(\"Liczba rozpatrywanych n-gramów: \") + str(n))\n",
    "\n",
    "# Liczba referencji\n",
    "refNmb = len(references)\n",
    "print(\"{0:<50}\".format(\"Liczba tłumaczeń referencyjnych (wzorcowych): \") + str(refNmb))\n",
    "\n",
    "# Maksymalna długość wzorca\n",
    "refMaxLength = getMaxLengthOflist(references)\n",
    "print(\"{0:<50}\".format(\"Maksymalna długość wzorca: \") + str(refMaxLength))\n",
    "\n",
    "# Długość kandydata\n",
    "canLength = len(candidate)\n",
    "print(\"{0:<50}\".format(\"Maksymalna długość kandydata: \") + str(canLength))\n",
    "\n",
    "# Unikalne słowa kandydata \n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące: \") + str(candidate))\n",
    "unique_candidate = makeUniqueList(candidate)\n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące bez powtórzeń: \") + str(unique_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d9812-d547-4572-8ccf-7f55c213e174",
   "metadata": {},
   "source": [
    "Wizuliacja i obliczenia BLEU: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Obliczenie końcowej wartości metryki wymaga przeanalizowania podanej liczby n-gramów. Poszczególne, analizowane n-gramy utworzone z tłumaczenia ocenianego zawiera pierwsza kolumna tabeli oznaczona jako <b>n-GRAM</b> (warto zauważyć, że ilość unigramów może być mniejsza od bigramów, ponieważ ewaluowane tłumaczenie może zawierać powtarzające się słowa). Każdy n-gram jest wyszukiwany w tłumaczeniach referencyjnych. Kolumna <b>Ref</b> z numerem tłumaczenia zawiera informacje ile razy dany n-gram wystąpił w tym tłumaczeniu. Następująca kolumna <b>Max Ref</b> jest maksymalną liczbą wystąpień wśród wszystkich tłumaczeniach wzorcowych. Kolumna <b>Count</b> zawiera informacje o ilości wystąpień n-gramu w tłumaczeniu ocenianym, a kolumna <b>Clip Count</b> przechowuje minimalną wartość z Count i Max Ref. Najwiażniejsza kolumna <b>Contribution</b> wskazuje \"wkład\" danej grupy n-gramów do wyniku końcowego. Jest to stosunek sumy kolumny Clip Count do liczebności danej grupy n-gramów (uwzględniając powtórzenia). Wprowadzony mechanizm obliczania wartości w kolumnie Clip Count jest zmodyfikowaną precyzją n-gramu i pozwala na uniknięcie sytujacji, w której tłumaczenie otrzymuje nienaturalnie dużą wartość metryki poprzez podanie w tłumaczeniu kandydującym powtarzającego się słowa z tłumaczenia referencyjnego. Przykładowo dla tłumaczeń wzorcowych: \"the cat is on the mat\" i \"there is a cat on the mat\" oraz tłumaczenia ocenianego \"the the the the the the the\" wkład unigramu \"the\" wynosi 2/7 zamiast 7/7.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8098dd8e-e140-47a5-b4a0-8b02a2620051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-GRAM\t\t\t\t\t\t\tRef1\tRef2\tRef3\tMax Ref Count\tClip Count\tContribution\n",
      "1)  It                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "2)  is                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "3)  a                   \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "4)  guide               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "5)  to                  \t\t\t\t1\t0\t1\t1\t1\t1\n",
      "6)  action              \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "7)  which               \t\t\t\t0\t1\t0\t1\t1\t1\n",
      "8)  ensures             \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "9)  that                \t\t\t\t2\t0\t0\t2\t1\t1\n",
      "10) the                 \t\t\t\t1\t4\t4\t4\t3\t3\n",
      "11) miliatry            \t\t\t\t1\t1\t0\t1\t1\t1\n",
      "12) always              \t\t\t\t0\t1\t1\t1\t1\t1\n",
      "13) obeys               \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "14) commands            \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "15) of                  \t\t\t\t0\t1\t1\t1\t1\t1\n",
      "16) party               \t\t\t\t0\t0\t1\t1\t1\t1\t\t16\\18\n",
      "\n",
      "1)  It is               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "2)  is a                \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "3)  a guide             \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "4)  guide to            \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "5)  to action           \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "6)  action which        \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "7)  which ensures       \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "8)  ensures that        \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "9)  that the            \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "10) the miliatry        \t\t\t\t1\t1\t0\t1\t1\t1\n",
      "11) miliatry always     \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "12) always obeys        \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "13) obeys the           \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "14) the commands        \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "15) commands of         \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "16) of the              \t\t\t\t0\t1\t1\t1\t1\t1\n",
      "17) the party           \t\t\t\t0\t0\t1\t1\t1\t1\t\t8\\17\n",
      "\n",
      "1)  It is a             \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "2)  is a guide          \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "3)  a guide to          \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "4)  guide to action     \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "5)  to action which     \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "6)  action which ensures\t\t\t\t0\t0\t0\t0\t1\t0\n",
      "7)  which ensures that  \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "8)  ensures that the    \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "9)  that the miliatry   \t\t\t\t1\t0\t0\t1\t1\t1\n",
      "10) the miliatry always \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "11) miliatry always obeys\t\t\t\t0\t0\t0\t0\t1\t0\n",
      "12) always obeys the    \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "13) obeys the commands  \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "14) the commands of     \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "15) commands of the     \t\t\t\t0\t0\t0\t0\t1\t0\n",
      "16) of the party        \t\t\t\t0\t0\t1\t1\t1\t1\t\t4\\16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zmienne pomocnicze\n",
    "tabs = '\\t\\t\\t\\t'\n",
    "listOfnmbOfGrams = []\n",
    "listOfResult = []\n",
    "listOfResult = []\n",
    "describeTable(refNmb)\n",
    "unique_candidate = makeUniqueList(candidate)\n",
    "\n",
    "# Pętla po liczbie n (liczbie rozpatrywanych n-gramów)\n",
    "for ngram in range(1, n + 1):\n",
    "    \n",
    "    # Suma wszystkich clipCount jednego n-gramu\n",
    "    sumClipCount = 0\n",
    "    counter = 1\n",
    "    # Liczba n-gramów:\n",
    "    if(ngram > 1):\n",
    "        unique_candidate = candidate\n",
    "    nmbOfGrams = len(unique_candidate) - ngram + 1\n",
    "    \n",
    "    # Pętla po liczbie n-gramów zależna od rozpatrywanego n-gramu\n",
    "    for idOfPattern in range(0, nmbOfGrams):\n",
    "        \n",
    "        gram = unique_candidate[idOfPattern]\n",
    "        # Pętla po liczbie słów do dodania aby otrzymać n-gram\n",
    "        for idToAdd in range(1, ngram):\n",
    "            gram = gram + ' ' + unique_candidate[idOfPattern + idToAdd]\n",
    "        \n",
    "        #Wypisanie początku wiersza tabeli\n",
    "        print(\"{0:<4}\".format(str(counter)+ \")\"), end='')\n",
    "        print(\"{0:<20}\".format(gram), end='')\n",
    "        print(tabs, end='')\n",
    "        \n",
    "        #Zmienne dla konkretnego n-gramu:\n",
    "        counter = counter + 1\n",
    "        maxRefCount = 0\n",
    "        count = 0\n",
    "        candidateWithoSpace = ' '.join(map(str, candidate))\n",
    "        count = getNumberOfOccurance(gram, candidateWithoSpace)\n",
    "        \n",
    "        # Sprawdzanie wystąpień n-gramu w referencjach\n",
    "        for reference in references:\n",
    "            referenceWithSpace = ' '.join(map(str, reference))\n",
    "            # Sprawdzenie wystąpienia konkretnego n-gramu w danej referencji\n",
    "            if(gram in referenceWithSpace):\n",
    "                gramOccurrances = getNumberOfOccurance(gram, referenceWithSpace)\n",
    "                print(str(gramOccurrances) + '\\t', end='')\n",
    "                maxRefCount = max(maxRefCount, gramOccurrances)\n",
    "            else:\n",
    "                print(\"0\" + '\\t', end='')\n",
    "        \n",
    "        # Obliczanie wartości sumClipCount\n",
    "        sumClipCount = sumClipCount + min(maxRefCount, count)\n",
    "        \n",
    "        #Wypisywanie maxRefCount i Coun\n",
    "        if(idOfPattern != nmbOfGrams - 1):\n",
    "            print(str(maxRefCount) + '\\t' + str(count) + '\\t' + str(min(maxRefCount, count)))\n",
    "        else:\n",
    "            print(str(maxRefCount) + '\\t' + str(count) + '\\t' + str(min(maxRefCount, count)), end ='')\n",
    "    \n",
    "    #Zapisanie wkładu danego n-gramu do oceny\n",
    "    if(ngram == 1):\n",
    "        listOfnmbOfGrams.append(canLength)\n",
    "    else:\n",
    "        listOfnmbOfGrams.append(nmbOfGrams)\n",
    "    listOfResult.append(sumClipCount)\n",
    "    print(\"\\t\\t\" + str(listOfResult[-1]) + \"\\\\\" + str(listOfnmbOfGrams[-1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177ba72-9df0-4266-a209-0d020ee21473",
   "metadata": {},
   "source": [
    "Obliczenie kary za różnice długości: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Metryka BLEU uwzględnia również różnice w długościach pomiędzy tłumaczeniem ocenianym, a referencyjnymi. Jest to przeprowadzane poprzez mnożenie metryki przez wartość <b>BP</b> (z ang. Brevity Penalty) liczoną zgodnie ze wzorem: <br>\n",
    "</p>\n",
    "Dla c > r lub c = r:\n",
    "$$\n",
    "  BP = 1 \n",
    "$$\n",
    "Dla c < r:\n",
    "$$\n",
    "  BP = e^{1-\\frac{r}{c}}\n",
    "$$\n",
    "$r$ - liczba słów w wzorcowym tłumaczeniu<br>\n",
    "$c$ - liczba słów w kandydowanym tłumaczeniu<br>\n",
    "Otrzymana kara jest z przedziału 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13e1a260-712b-475a-ae66-ca7c351738f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maksymalna długość tłumaczenia wzorcowego: 18\n",
      "Długość tłumaczenia kandydującego: 18\n",
      "BP: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Kara stratności:\n",
    "refLength = refMaxLength\n",
    "print(\"\\nMaksymalna długość tłumaczenia wzorcowego: \" + str(refLength))\n",
    "canLength = len(candidate)\n",
    "print(\"Długość tłumaczenia kandydującego: \" + str(canLength))\n",
    "bp = lengthPenalty(refLength, canLength)\n",
    "print(\"BP: \" + str(bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe736b-392a-49fc-9f53-982514e0992f",
   "metadata": {},
   "source": [
    "Ostateczy wynik: <br>\n",
    "Końcowa wartość metryki jest liczona zgodnie ze wzorem:\n",
    "$$\n",
    "  BLUE = BP * exp \\Biggl ( \\sum \\limits_{n=1} ^{N} w_{n} log (p_{n}) \\Biggr )\n",
    "$$\n",
    "$N$ - liczba rozważanym n-gramów (otrzymana na podstawie zadeklarowanych wag w liście \"weights\")<br>\n",
    "$w_{n}$ - waga danego n-gramu (podana w liście \"weights\")<br>\n",
    "$p_{n}$ - stosunek wystąpień danego n-gramu do wszystkich n-gramów (wartość odczytana z kolumny \"Contribution\" dla danego n-gramu)<br>\n",
    "Końcowa wartość metryki powinna być z przedziału 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2004426f-b569-4fa8-87c2-8ad62040de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLUE = 1.000 exp(  ln( 16/18 ) + ln( 8/17 ) + ln( 4/16 ) ) = 0.5686658363061537\n"
     ]
    }
   ],
   "source": [
    "calculateResult(listOfResult, listOfnmbOfGrams, bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95ac13-2e90-43b3-a24e-682814467437",
   "metadata": {},
   "source": [
    "Obliczenie wzorcowego BLEU: <br>\n",
    "Wartość metryki BLEU otrzymana przez gotowy pakiet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e40bd9c-a6db-4803-9e7d-ea224b9335df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wzorcowe BLEU Score:  0.7311104457090247\n"
     ]
    }
   ],
   "source": [
    "print(\"Wzorcowe BLEU Score: \", bleu.sentence_bleu(references, candidate, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e3b8a-9553-4d35-b23b-01b0b9b826ea",
   "metadata": {},
   "source": [
    "<b>Problemy metryki BLEU</b> <br>\n",
    "<a class=\"anchor\" id =\"BLEU_P\"></a>\n",
    "Wiele badań potwierdziło korelację wartości metryki BLEU oceną ludzką. Zauważa się jednak pewne problemy tej metryki:\n",
    "* Punkty dla słów posiadają taką samą wagę, więc zdania niekompletne nie są w żaden sposób niżej oceniane\n",
    "* Synonimy i parafrazy są brane pod uwagę wyłącznie wtedy, gdy występują w zbiorze tłumaczeń referencyjnych\n",
    "* Tłumaczenia otrzymujące podobne wartości metryki mogą uzyskać skrajne wartości w ocenie ludzkiej ze wględu na możliwości oszukania metryki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc74cfd-9c7c-4126-a8bf-3383c31b2ee9",
   "metadata": {},
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012cdad-05c4-4fdf-a185-5523e0fd63b5",
   "metadata": {},
   "source": [
    "**<font color='red'>M</font>etric for <font color='red'>E</font>valuation of <font color='red'>T</font>ranslation with <font color='red'>E</font>xplicit <font color='red'>OR</font>dering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bddbba-a9be-4ee5-873e-5d566fd4aedb",
   "metadata": {},
   "source": [
    "Metryka używana do oceny tłumaczenia maszynowego. Operta na średniej harmonicznej n-gramów precyzji i pokrycia z przyznaniem większej wagi dla pokrycia. Cechą charakterystyczną tej metryki jest dopasowywanie synonimów - akceptowanie wyrazów o podobnym znaczeniu. Powodem powstania tej metryki jest próba wyeliminowania błędów pojawiających się w metryce BLEU. Główna różnicą pomiędzy tymi metrykami jest poziom szukania korelacji. BLUE skupia się na poziomie całego korpusy, natomiast METEOR na poziomie zdań i segmentów.\n",
    "<br><br>\n",
    "<b>Działanie: </b> <br>\n",
    "METEOR w celu oszacowania jakości tłumaczenia maszynowego porównuje je z jednym/dwoma tłumaczeniami wzorcowymi. Wynik ewaluacji jest obliczany osobno dla każdego zdania w taki sposób, że każde zdanie z tłumaczenia maszynowego jest porównywane ze zdaniem z tłumaczenia wzorcowego, a następnie do dalszej analizy brana jest pod uwagę lepsza ocena. Metryka METEOR posługuje się dwoma etapami:\n",
    "* Etap pierwszy: <br> METEOR ALIGNER - tworzenie odwzorowania pomiędzymi tłumaczeniami\n",
    "* Etap drugi: <br> METEOR SCORER - obliczanie końcowego wyniku\n",
    "\n",
    "Etap pierwszy:<br>\n",
    "Etap pierwszy dzieli się na dwa zasadniczne kroki: zidentyfikowanie wszystkich odwzorowań pomiędzy tłumaczeniem ocenianym a wzorcowym i wyselekcjonowanie najlepszego odwzorowania. <br>\n",
    "\n",
    "Identyfikacja odwzorowań: <br>\n",
    "Odwzorowanień w metryce METEOR jest lista słów z tłumaczenia wzorcowego, które w jakiś spoób odpowiadają słowu z tłumaczenia maszynowego. Proces dopasowywania jest realizowany poprzez cztery moduły:\n",
    "* exact - dopasowanie słów identycznych\n",
    "* stem - dopasowanie słów o identycznym rdzeniu\n",
    "* synonym - dopasowanie słów bliskoznacznych według bazy WorldNet\n",
    "* paraphrase - dopasowanie fraz wymienionych jako parafrazy w tabeli parafrazowej\n",
    "\n",
    "Przykład: <br>\n",
    "Tłumaczenie maszynowe (T): Chłopak bajkę opowiadał bez ogródek <br>\n",
    "Tłumaczenie wzorcowe (T): Chłopczyk opowiada historię bez owijania w bawełnę <br>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"METEOR_schemat.png\"/>\n",
    "</p>\n",
    "\n",
    "Wyselekcjonowanie najlepszego odwzorowania:\n",
    "Krok ten polega na znalezieniu największego podzbioru dopasowań wśród dopasowań znalezionych w pierwszym etapie i spełniających kryteria:\n",
    "* Każde słowo może należeć tylko do jednego dopasowania\n",
    "* Dopasowywana jest możliwie największa liczba słów w obu tłumaczeniach\n",
    "* W wyniku wybranych dopasowań występuje możliwie najmniejsza liczba fraz przylegających do siebie i występujących w tej samej kolejności w obu tłumaczeniach\n",
    "* Pomiędzy pozycjami startowymi dopasowań wystąpi jak najmniejsza suma odstępów - faworyzowanie dopasowań na podobnych pozycjach w obu tłumaczeniach\n",
    "\n",
    "Najlepsze dopasowanie:\n",
    "<p align=\"center\">\n",
    "  <img src=\"METEOR_schemat2.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd4250-886e-4e36-b826-8fa274c13c71",
   "metadata": {},
   "source": [
    "Etap drugi:<br>\n",
    "Celem etapu drugiego jest obliczenie wyniku końcowego metryki na podstawie wyniku pierwszego etapu. Końcowy wynik oparty jest na kilku wartościach:\n",
    "* Precyzja<br>\n",
    "Stosunek dopasowań wyrazów w ocenianym tłumaczeniu do wszystkich wyrazów tłumaczenia.\n",
    "$$\n",
    "  P = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(t)}{|t|}\n",
    "$$\n",
    "$n$ - liczba modułów biorących udział w dopasowaniu<br>\n",
    "$w_{i}$ - waga i-tego modułu<br>\n",
    "$m_{i}(t)$ - liczb wyrazów dopasowanych przez i-ty moduł<br>\n",
    "$|t|$ - liczba wszystkich wyrazów w tłumaczeniu<br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(t) + w_{stem} * m_{stem}(t) + w_{synonym} * m_{synonym}(t) + w_{paraphrase} * m_{paraphrase}(t) }{6}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$\n",
    "* Pokrycie <br>\n",
    "Stosunek wyrazów w tłumaczeniu wzorcowym, które zostały dopasowane w tłumaczeniu maszynowym do wszystkich wyrazów tłumaczenia wzorcowego.\n",
    "$$\n",
    "  R = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(r)}{|r|}\n",
    "$$\n",
    "$m_{i}(r)$ - liczba wyrazów dopasowanych w tłumaczeniu referencyjnym<br>\n",
    "$|r|$ - liczba wyrazów tłumaczenia wzorcowego <br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(r) + w_{stem} * m_{stem}(r) + w_{synonym} * m_{synonym}(r) + w_{paraphrase} * m_{paraphrase}(r) }{6}\n",
    "$$\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff8acf-a6b6-4314-a1ba-ab6962438672",
   "metadata": {},
   "source": [
    "BLEU:\n",
    "* https://towardsdatascience.com/bleu-bilingual-evaluation-understudy-2b4eab9bcfd1\n",
    "BLEU i METEOR:\n",
    "* http://docplayer.pl/14218168-Ewaluacja-systemow-tlumaczenia-automatycznego.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755c315-d803-4143-bf6a-584967d58740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
