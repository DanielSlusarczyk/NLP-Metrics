{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fca8cd8-67ea-49ea-ad53-f0f0676fcf9f",
   "metadata": {},
   "source": [
    "## Projekt Indywidualny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed205819-c5d2-4a22-a126-1196cc7fab40",
   "metadata": {},
   "source": [
    "Autor: <b>Daniel Ślusarczyk</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b5c04-b05b-49ef-829c-6f4f2f91cbc5",
   "metadata": {},
   "source": [
    "Opiekun projektu: <b>mgr inż. Mateusz Bartosiewicz<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186a5bd-49ca-4bdd-974d-2eb6b29e2716",
   "metadata": {},
   "source": [
    "## Spis Treści:\n",
    "1. [Cel projektu](#CP)\n",
    "2. [NLP](#NLP)\n",
    "3. [Potrzebne instalacje](#PI)\n",
    "4. [Metryki](#M)\n",
    "    1. [BLEU](#BLEU)\n",
    "        1. [Opis](#BLEU_O)\n",
    "        2. [Działanie](#BLEU_D)\n",
    "        3. [Problemy](#BLEU_P)\n",
    "    2. [METOR](#METEOR)\n",
    "        1. [Opis](#METEOR_O)\n",
    "        2. [Działanie](#METEOR_D)\n",
    "        2. [Problemy](#METEOR_P)\n",
    "    3. [ROUGE](#ROUGE)\n",
    "        1. [Opis](#ROUGE_O)\n",
    "        2. [ROUGE-N](#ROUGE_N)\n",
    "            1. [Działanie](#ROUGE_N_D)\n",
    "        3. [ROUGE-L](#ROUGE_L)\n",
    "            1. [Działanie](#ROUGE_L_D)\n",
    "        3. [Problemy](#ROUGE_P)\n",
    "    4. [WMD](#WMD)\n",
    "        1. [Opis](#WMD_O)\n",
    "        2. [Działanie](#WMD_D)\n",
    "        3. [Problemy](#WMD_P)\n",
    "    5. [CIDEr](#CIDER)\n",
    "        1. [Opis](#CIDER_O)\n",
    "        2. [Działanie](#CIDER_D)\n",
    "        3. [CIDEr-D](#CIDER_D_D)\n",
    "5. [Sposoby porównywania tesktów](#SPT)\n",
    "6. [Embeddings dla NLP](#EDN)\n",
    "7. [Zbiór COCO](#ZC)\n",
    "8. [Serwer ewauacyjny COCO](#SEC)\n",
    "9. [Źródła](#SOURCE)\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0b6d8-96e1-4fd4-93f1-bf61331cb411",
   "metadata": {},
   "source": [
    "<a name=\"CP\"></a>\n",
    "### Cel projektu\n",
    "<p style='text-align: justify;'>\n",
    "Celem projektu jest opracowanie teoretyczne narzędzi do analizy NLP. Projekt zakłada prezentację działania poszczególnych metryk i zagadnień związanych z ewaluacją napisów. Poruszanym aspektem są również opracowane narzędzia do ewaluacji i sposoby ich używania.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7806-43a0-4b6b-97dc-76e2e55a50e8",
   "metadata": {},
   "source": [
    "### Potrzebne instalacje\n",
    "<a name=\"PI\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "W celu wizualizacji sposobu działania niektórych metryk niezbędna jest instalacja dodatkowych pakietów, które nie są dostępne w standardowym języku Pythonie. Niezainstalowanie tych pakietów wiąże się z niewłaściwym działaniem kodu znajdującego się w poniższych punktach.\n",
    "</p>\n",
    "\n",
    "Niezbędne instalacje:\n",
    "* Metryka ROUGE - Python rouge library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e33ee-4841-488f-a72a-61fab7d443a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pakiety do liczenia wzorcowego ROUGE\n",
    "import sys\n",
    "!{sys.executable} -m pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a158b5f-c1a5-4306-8c39-7417ebb1b1f8",
   "metadata": {},
   "source": [
    "* Metryka WMD - NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0095eb07-a9c0-4c0e-9fe8-582c0feb3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pakiety do usuwania \"przerywników\"\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1520a-1777-400a-96e9-98349ba54343",
   "metadata": {},
   "source": [
    "<a id =\"NLP\"></a>\n",
    "### NLP - Przetwarzanie Języka Naturalnego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633653e0-936b-4481-b606-70cc3885a22f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style='text-align: justify;'>\n",
    "NLP (z ang. Natural Leanguage Processing) jest to interdyscyplinarna dziedzina, oparta na podstawach sztucznej inteligencji i językoznawstwa.\n",
    "Zajmuje się automatyzacją analizy, rozumienia, tłumaczenia i generowania języka naturalnego przez komputer.  Istnieją dwa fundamentalne kierunki przepływu informacji w NLP, które stanowią główną problematykę tej dziedziny . System, który zawiera informacje zapisane w bazie danych w sposób techniczny i zrozumiały wyłącznie dla osób zaznajomionych ze sposobem zapisu przekształca się w informacje przedstawione w sposób zrozumiały dla wszystkich osób posługujących się danym językiem. Z drugiej strony system, który rozumie język naturalny modyfikuje go na formalne symbole możliwe do przetworzenia przez system komputerowy. W konsekwencji problematyka NLP dotyczy zarówno generacji i rozumienia języka.\n",
    "</p>\n",
    "<br>\n",
    "<b>Problemy stojące przed NLP:</b> \n",
    "<br>\n",
    "Ze względu na niezwykłe rozbudowanie i skomplikowanie języka naturalnego można wyróżnić wiele problemów, z którymi wiąże się dziedzina NLP:\n",
    "<ul>\n",
    "<li> Segmentacja sygnału mowy - stwierdzenie występowania w sygnale mowy przerwy pomiędzy kolejnymi znakami jest skomplikowanym zadaniem ze względu na wpływ szybkości mowy, semantyki i gramatyki charakterystycznej dla danego języka. </li>\n",
    "<li> Segmentacja tekstu - istnieją języki, w których nie istnieją wyraźne granice pomiędzy wyrazami. </li>\n",
    "<li> Wieloznaczność słów - znaczenie danego słowa może wymagać rozpatrywania go w kontekście większej ilości słów. Zadaniem NLP jest określenie takiego znaczenia. </li>\n",
    "<li> Syntaktyczna niejednoznaczność - analiza języka naturalnego może prowadzić do gramatycznej dwuznaczności. NLP odpowiada za rozpatrzenie danego fragmentu w kontekście i stwierdzenie poprawnej wersji. </li>\n",
    "<li> Nieprawidłowe i nieregularne dane - wykrywanie literówek i niepoprawnej składni w tekście pisanym lub błednej wymowy, regionalizmów, akcentów w sygnale mowy. </li>\n",
    "<li> Akt mowy i plan - analiza sytuacji, w której występuje związek pomiędzy czynnością, a mową. </li>\n",
    "</ul>\n",
    "<b> Przykładowe zadania NLP:</b>\n",
    "<ul>\n",
    "<li> Automatyczna sumaryzacja – program umożliwiający streszczenie dłuższego tekstu w krótszy o tym samym przesłaniu i najważniejszych informacjach</li>\n",
    "<li> Synteza mowy – operacja polegająca na przetwarzaniu języka na mowę</li>\n",
    "<li> Korekcja tekstu – analiza tekstu i wykrywanie błędów</li>\n",
    "<li> Rozpoznawanie mowy – operacja polegająca na przetwarzaniu mowy na tekst </li>\n",
    "</ul>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006d249-29de-44e7-bd07-b5f404a225e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metryki \n",
    "<a class=\"anchor\" id =\"M\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2d274-6a4b-4e26-8c92-a05d7e0af6e0",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Wzmożony rozwój NLP skutkuje zwiększoną potrzebą oceny jakosci powstających systemów automatycznego przetwarzania języka naturalnego. Metryki są nieodłączonym elementem uczenia maszynowego. Służą do oceny spełnienia oczekiwań stawianych przed rozwiązaniem problememu, do którego używany jest ewaluowany system.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8d204-3929-44ac-a886-7856f8ab5975",
   "metadata": {},
   "source": [
    "### BLEU\n",
    "<a class=\"anchor\" id =\"BLEU\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51175e7d-4bba-4167-a56b-0d8d7c6368e4",
   "metadata": {},
   "source": [
    "<b><font color='red'>B</font>i<font color='red'>L</font>ingual <font color='red'>E</font>valuation <font color='red'>U</font>nderstudy</b>\n",
    "<a class=\"anchor\" id =\"BLEU_O\"></a>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "Ewaluacja służąca do mierzenia jakości modeli tłumaczenia maszynowego kierująca się zasadą \"im bliższe tłumaczenie automatyczne i profesjonalne ludzkie tłumaczenie, tym lepiej\". Zadaniem tej metryki jest ocena jak dobrze model tłumaczy tekst pomiędzy językami. W przypadku tej metryki \"jakość\" rozumiana jest jako korelacja pomiędzy danymi wyjściowymi a tekstem ludzkim. Został przedstawiony w 2002 roku i opisany w raporcie firmy IBM. BLEU jest jedną z pierwszych metryk, której udało się uzyskać wyniki zbliżone z ludzkim osądem. W konsekwencji stała się najbardziej popularną metodą, pomimo pewnych wad.\n",
    "</p>\n",
    "\n",
    "<b>Działanie</b><br>\n",
    "<a id =\"BLEU_D\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "Działanie metryki zostanie przedstawione na podstawie kodu, który krok po kroku przeprowadza potrzebne operacje w celu obliczenia wartości metryki. Prezentowany kod ma charakter prezentacyjny i wizualizuje wiele informacji w celu łatwiejszego zrozumienia działania metryki. Wynik uzyskany przez kod jest możliwy do porównania ze wzorcowym wynikiem.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d791e-962b-4e0f-a5ea-fc018e3cf720",
   "metadata": {},
   "source": [
    "Import potrzebnych pakietów: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Pakiet \"nltk.translate.bleu_score\" importowany jako alias \"bleu\" służy do uzyskania wzorcowego wyniku na końcu przykładu w celu porównania go z wynikiem uzyskanym przez\n",
    "kod.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eef6121-c0e2-4a3a-ab0b-45a05740add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wzorcowa wartość BLEU:\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f755473-d072-4e18-8e21-5cc74980f361",
   "metadata": {},
   "source": [
    "Analizowane dane: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Metryka BLEU opiera działanie na porównywaniu n-gramów tłumaczenia kandydata z n-gramami tłumaczeń wzorcowych (miejsce wystąpienia analizowanego n-gramu w tłumaczeniu kandydatującym i wzorcu nie ma znaczenia). Im większa liczba wspólnych n-gramów pomiędzy kandydatem i wzorcem tym tłumaczenie jest uznawane za lepsze. Metryka BLEU pozwala na dostosowanie wag poszczególnych n-gramów i przypisanie większej wartości n-gramom, które powinny być szczególnie uwzględniane. Wartość listy <b>weights</b> służy do podania wag dla poszczególnych n-gramów. Podanie wartości 0 jest jednoznaczne z wyzerowaniem wpływu danego n-gramu na wynik końcowy. Niepodanie żadnej wartości pozwala całkowicie wykluczyć ostatnie n-gramy z analizy. Lista <b>references</b> służy do podania wzorcowych tłumaczeń dla danego tłumaczenia kandydującego <b>candidate</b>. Sposób prawidłowego wpisania tych danych jest przedstawiony poniżej.<br>\n",
    "</p>\n",
    "Przykłady: <br>\n",
    "weights = (0.25) - uwzględnienie w obliczeniach jedynie unigramów <br>\n",
    "weights = (0, 0, 0.25) - uwzględnienie w wyniku jedynie trigramów. Przeprowadzenie analizy dla unigramów, bigramów i trigramów <br>\n",
    "weights = (0.2, 0.3, 0.4, 0.5) - uwzględnienie w obliczeniach od unigramu do 4-gramu z przypisaniem kolejno wag: 0.2, 0.3, 0.4, 0.5 <br>\n",
    "references = ['Recepcjonista poinformował o zamknięciu hotelu'.split(), 'Pracownik recepcji poinformował o zamknięciu hotelu'.split()] - zdefiniowanie dwóch tłumaczeń wzorcowych dla tłumaczenia kandydującego <br>\n",
    "references = ['Recepcjonista poinformował o zamknięciu hotelu'.split()] - zdefiniowanie jednego tłumaczenia wzorcowego dla tłumaczenia kandydującego <br>\n",
    "candidate = 'Pan pracujący na recepecji udzielił informacji o zamknięciu hotelu'.split() - zdefiniowanie ocenianego tłumaczenia (kandydata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b586094b-c7d7-4602-8ef6-8429fdc2e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.BLEU_functions import *\n",
    "# Wagi przypisane do poszczególnych n-gramów:\n",
    "weights = [0.25, 0.25]\n",
    "\n",
    "# Tłumaczenia referencyjne\n",
    "references = [\n",
    "            'It is a guide to action which ensures that the miliatry always obeys the commands of the party',\n",
    "            'It is a guide to action which ensures that the miliatry always obeys the commands of the party',\n",
    "            'It is a guide to action which ensures that the miliatry always obeys the commands of the party'\n",
    "            ]\n",
    "references = splitList(references)\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'It is a guide to action which ensures that the miliatry always obeys the commands of the party'\n",
    "candidate = candidate.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655620e-212e-4f5f-8481-19e180f7e6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0190f9c5-60d4-424f-a2e8-401a38720ebd",
   "metadata": {},
   "source": [
    "Potwierdzenie danych: <br>\n",
    "Wykonanie poniższego kodu pozwala na potwierdzenie poprawności wprowadzonych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3039a319-5307-46c1-ae14-c6ac32c928ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba rozpatrywanych n-gramów:                   2\n",
      "Liczba tłumaczeń referencyjnych (wzorcowych):     3\n",
      "Maksymalna długość wzorca:                        18\n",
      "Maksymalna długość kandydata:                     18\n",
      "Tłumaczenie kandydujące:                          ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
      "Tłumaczenie kandydujące bez powtórzeń:            ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'miliatry', 'always', 'obeys', 'commands', 'of', 'party']\n"
     ]
    }
   ],
   "source": [
    "# Ilość analizowanych n-gramów\n",
    "n = getNumberOfnGram(weights)\n",
    "print(\"{0:<50}\".format(\"Liczba rozpatrywanych n-gramów: \") + str(n))\n",
    "\n",
    "# Liczba referencji\n",
    "refNmb = len(references)\n",
    "print(\"{0:<50}\".format(\"Liczba tłumaczeń referencyjnych (wzorcowych): \") + str(refNmb))\n",
    "\n",
    "# Maksymalna długość wzorca\n",
    "refMaxLength = getMaxLengthOflist(references)\n",
    "print(\"{0:<50}\".format(\"Maksymalna długość wzorca: \") + str(refMaxLength))\n",
    "\n",
    "# Długość kandydata\n",
    "canLength = len(candidate)\n",
    "print(\"{0:<50}\".format(\"Maksymalna długość kandydata: \") + str(canLength))\n",
    "\n",
    "# Unikalne słowa kandydata \n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące: \") + str(candidate))\n",
    "unique_candidate = makeUniqueList(candidate)\n",
    "print(\"{0:<50}\".format(\"Tłumaczenie kandydujące bez powtórzeń: \") + str(unique_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d9812-d547-4572-8ccf-7f55c213e174",
   "metadata": {},
   "source": [
    "Wizuliacja i obliczenia BLEU: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Obliczenie końcowej wartości metryki wymaga przeanalizowania podanej liczby n-gramów. Poszczególne, analizowane n-gramy utworzone z tłumaczenia ocenianego zawiera pierwsza kolumna tabeli oznaczona jako <b>n-GRAM</b> (warto zauważyć, że ilość unigramów może być mniejsza od bigramów, ponieważ ewaluowane tłumaczenie może zawierać powtarzające się słowa). Każdy n-gram jest wyszukiwany w tłumaczeniach referencyjnych. Kolumna <b>Ref</b> z numerem tłumaczenia zawiera informacje ile razy dany n-gram wystąpił w tym tłumaczeniu. Następująca kolumna <b>Max Ref</b> jest maksymalną liczbą wystąpień wśród wszystkich tłumaczeniach wzorcowych. Kolumna <b>Count</b> zawiera informacje o ilości wystąpień n-gramu w tłumaczeniu ocenianym, a kolumna <b>Clip Count</b> przechowuje minimalną wartość z Count i Max Ref. Najwiażniejsza kolumna <b>Contribution</b> wskazuje \"wkład\" danej grupy n-gramów do wyniku końcowego. Jest to stosunek sumy kolumny Clip Count do liczebności danej grupy n-gramów (uwzględniając powtórzenia). Wprowadzony mechanizm obliczania wartości w kolumnie Clip Count jest zmodyfikowaną precyzją n-gramu i pozwala na uniknięcie sytujacji, w której tłumaczenie otrzymuje nienaturalnie dużą wartość metryki poprzez podanie w tłumaczeniu kandydującym powtarzającego się słowa z tłumaczenia referencyjnego. \n",
    "<br>\n",
    "Przykładowo dla tłumaczeń wzorcowych: \"the cat is on the mat\" i \"there is a cat on the mat\" oraz tłumaczenia ocenianego \"the the the the the the the\" wkład unigramu \"the\" wynosi 2/7 zamiast 7/7.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8098dd8e-e140-47a5-b4a0-8b02a2620051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-GRAM\t\t\t\t\t\t\tRef1\tRef2\tRef3\tMax Ref Count\tClip Count\tContribution\n",
      "1)  It                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "2)  is                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "3)  a                   \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "4)  guide               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "5)  to                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "6)  action              \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "7)  which               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "8)  ensures             \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "9)  that                \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "10) the                 \t\t\t\t3\t3\t3\t3\t3\t3\n",
      "11) miliatry            \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "12) always              \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "13) obeys               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "14) commands            \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "15) of                  \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "16) party               \t\t\t\t1\t1\t1\t1\t1\t1\t\t18\\18\n",
      "\n",
      "1)  It is               \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "2)  is a                \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "3)  a guide             \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "4)  guide to            \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "5)  to action           \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "6)  action which        \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "7)  which ensures       \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "8)  ensures that        \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "9)  that the            \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "10) the miliatry        \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "11) miliatry always     \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "12) always obeys        \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "13) obeys the           \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "14) the commands        \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "15) commands of         \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "16) of the              \t\t\t\t1\t1\t1\t1\t1\t1\n",
      "17) the party           \t\t\t\t1\t1\t1\t1\t1\t1\t\t17\\17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printTable(n, refNmb, candidate, references, canLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177ba72-9df0-4266-a209-0d020ee21473",
   "metadata": {},
   "source": [
    "Obliczenie kary za różnice długości: <br>\n",
    "<p style='text-align: justify;'>\n",
    "Metryka BLEU uwzględnia również różnice w długościach pomiędzy tłumaczeniem ocenianym, a referencyjnymi. Jest to przeprowadzane poprzez mnożenie metryki przez wartość <b>BP</b> (z ang. Brevity Penalty) liczoną zgodnie ze wzorem: <br>\n",
    "</p>\n",
    "Dla c > r lub c = r:\n",
    "$$\n",
    "  BP = 1 \n",
    "$$\n",
    "Dla c < r:\n",
    "$$\n",
    "  BP = e^{1-\\frac{r}{c}}\n",
    "$$\n",
    "$r$ - liczba słów w wzorcowym tłumaczeniu<br>\n",
    "$c$ - liczba słów w kandydowanym tłumaczeniu<br>\n",
    "Otrzymana kara jest z przedziału 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e1a260-712b-475a-ae66-ca7c351738f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maksymalna długość tłumaczenia wzorcowego: 18\n",
      "Długość tłumaczenia kandydującego: 18\n",
      "BP: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Kara stratności:\n",
    "refLength = refMaxLength\n",
    "print(\"\\nMaksymalna długość tłumaczenia wzorcowego: \" + str(refLength))\n",
    "canLength = len(candidate)\n",
    "print(\"Długość tłumaczenia kandydującego: \" + str(canLength))\n",
    "bp = lengthPenalty(refLength, canLength)\n",
    "print(\"BP: \" + str(bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe736b-392a-49fc-9f53-982514e0992f",
   "metadata": {},
   "source": [
    "Ostateczy wynik: <br>\n",
    "Końcowa wartość metryki jest liczona zgodnie ze wzorem:\n",
    "$$\n",
    "  BLUE = BP * exp \\Biggl ( \\sum \\limits_{n=1} ^{N} w_{n} log (p_{n}) \\Biggr )\n",
    "$$\n",
    "$N$ - liczba rozważanym n-gramów (otrzymana na podstawie zadeklarowanych wag w liście \"weights\")<br>\n",
    "$w_{n}$ - waga danego n-gramu (podana w liście \"weights\")<br>\n",
    "$p_{n}$ - stosunek wystąpień danego n-gramu do wszystkich n-gramów (wartość odczytana z kolumny \"Contribution\" dla danego n-gramu)<br>\n",
    "Końcowa wartość metryki powinna być z przedziału 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2004426f-b569-4fa8-87c2-8ad62040de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLUE [2] = 1.000 exp( 0.25 ln( 18/18 ) + 0.25 ln( 17/17 ) ) = 1.0\n"
     ]
    }
   ],
   "source": [
    "calculateResult(bp, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95ac13-2e90-43b3-a24e-682814467437",
   "metadata": {},
   "source": [
    "Obliczenie wzorcowego BLEU: <br>\n",
    "Wartość metryki BLEU otrzymana przez gotowy pakiet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e40bd9c-a6db-4803-9e7d-ea224b9335df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wzorcowe BLEU Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Wzorcowe BLEU Score: \", bleu.sentence_bleu(references, candidate, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e3b8a-9553-4d35-b23b-01b0b9b826ea",
   "metadata": {},
   "source": [
    "<b>Problemy metryki BLEU</b> <br>\n",
    "<a class=\"anchor\" id =\"BLEU_P\"></a>\n",
    "Wiele badań potwierdziło korelację wartości metryki BLEU oceną ludzką. Zauważa się jednak pewne problemy tej metryki:\n",
    "* Punkty dla słów posiadają taką samą wagę, więc zdania niekompletne nie są w żaden sposób niżej oceniane\n",
    "* Synonimy i parafrazy są brane pod uwagę wyłącznie wtedy, gdy występują w zbiorze tłumaczeń referencyjnych\n",
    "* Tłumaczenia otrzymujące podobne wartości metryki mogą uzyskać skrajne wartości w ocenie ludzkiej ze wględu na możliwości oszukania metryki (szczególnie wczesnych wersji metryki BLEU)\n",
    "* Nie jest rozważana waga danych słów. W takim samym stopniu na wynik końcowy wpływa wystąpienie przyimków, jak zwrotów szczególnie ważnych dla tłumaczenia.\n",
    "* W przypadku oparcia metryki BLEU na unigramach kolejność słów nie ma żadnego znaczenia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc74cfd-9c7c-4126-a8bf-3383c31b2ee9",
   "metadata": {},
   "source": [
    "### METEOR\n",
    "<a id =\"METEOR_O\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012cdad-05c4-4fdf-a185-5523e0fd63b5",
   "metadata": {},
   "source": [
    "**<font color='red'>M</font>etric for <font color='red'>E</font>valuation of <font color='red'>T</font>ranslation with <font color='red'>E</font>xplicit <font color='red'>OR</font>dering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bddbba-a9be-4ee5-873e-5d566fd4aedb",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "METEOR to metryka używana do oceny tłumaczenia maszynowego. Została opracowana i wydana w 2004 roku z przeznaczeniem osiągnięcia wysokiej korelacji z ludzkim osądem. Oparta jest na średniej harmonicznej n-gramów precyzji i pokrycia z przyznaniem większej wagi dla pokrycia. Cechą charakterystyczną tej metryki jest dopasowywanie synonimów - akceptowanie wyrazów o podobnym znaczeniu. Powodem powstania tej metryki jest próba wyeliminowania błędów pojawiających się w metryce BLEU. Główna różnicą pomiędzy tymi metrykami jest poziom szukania korelacji. BLUE skupia się na poziomie całego korpusu, natomiast METEOR na poziomie zdań i segmentów.\n",
    "<\\p>\n",
    "<br><br>\n",
    "<b>Działanie: </b> <br>\n",
    "<a id =\"METEOR_D\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "METEOR w celu oszacowania jakości tłumaczenia maszynowego porównuje je z jednym/dwoma tłumaczeniami wzorcowymi. Wynik ewaluacji jest obliczany osobno dla każdego zdania w taki sposób, że każde zdanie z tłumaczenia maszynowego jest porównywane ze zdaniem z tłumaczenia wzorcowego, a następnie do dalszej analizy brana jest pod uwagę lepsza ocena. \n",
    "<\\p>\n",
    "Metryka METEOR posługuje się dwoma etapami:\n",
    "\n",
    "* Etap pierwszy: <br> METEOR ALIGNER - tworzenie odwzorowania pomiędzymi tłumaczeniami\n",
    "* Etap drugi: <br> METEOR SCORER - obliczanie końcowego wyniku\n",
    "\n",
    "    \n",
    "Etap pierwszy:<br>\n",
    "Etap pierwszy dzieli się na dwa zasadniczne kroki: zidentyfikowanie wszystkich odwzorowań pomiędzy tłumaczeniem ocenianym a wzorcowym i wyselekcjonowanie najlepszego odwzorowania. <br>\n",
    "\n",
    "Identyfikacja odwzorowań: <br>\n",
    "Odwzorowanień w metryce METEOR jest lista słów z tłumaczenia wzorcowego, które w jakiś spoób odpowiadają słowu z tłumaczenia maszynowego. Proces dopasowywania jest realizowany poprzez cztery moduły:\n",
    "* exact - dopasowanie słów identycznych\n",
    "* stem - dopasowanie słów o identycznym rdzeniu\n",
    "* synonym - dopasowanie słów bliskoznacznych według bazy WorldNet\n",
    "* paraphrase - dopasowanie fraz wymienionych jako parafrazy w tabeli parafrazowej\n",
    "\n",
    "Przykład: <br>\n",
    "Tłumaczenie maszynowe (T): Kot siedzi na ganku na złość <br>\n",
    "Tłumaczenie wzorcowe (T): Kotek na przekór siedział na płocie <br>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"teoria/METEOR_schemat.png\"/>\n",
    "</p>\n",
    "\n",
    "Wyselekcjonowanie najlepszego odwzorowania:\n",
    "Krok ten polega na znalezieniu największego podzbioru dopasowań wśród dopasowań znalezionych w pierwszym etapie i spełniających kryteria:\n",
    "* Każde słowo może należeć tylko do jednego dopasowania\n",
    "* Dopasowywana jest możliwie największa liczba słów w obu tłumaczeniach\n",
    "* W wyniku wybranych dopasowań występuje możliwie najmniejsza liczba fraz przylegających do siebie i występujących w tej samej kolejności w obu tłumaczeniach\n",
    "* Pomiędzy pozycjami startowymi dopasowań wystąpi jak najmniejsza suma odstępów - faworyzowanie dopasowań na podobnych pozycjach w obu tłumaczeniach\n",
    "\n",
    "Najlepsze dopasowanie:\n",
    "<p align=\"center\">\n",
    "  <img src=\"teoria/METEOR_schemat2.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd4250-886e-4e36-b826-8fa274c13c71",
   "metadata": {},
   "source": [
    "Etap drugi:<br>\n",
    "Celem etapu drugiego jest obliczenie wyniku końcowego metryki na podstawie wyniku pierwszego etapu. Końcowy wynik oparty jest na kilku wartościach:\n",
    "* Precyzja<br>\n",
    "Stosunek dopasowań wyrazów w ocenianym tłumaczeniu do wszystkich wyrazów tłumaczenia.\n",
    "$$\n",
    "  P = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(t)}{|t|}\n",
    "$$\n",
    "$n$ - liczba modułów biorących udział w dopasowaniu<br>\n",
    "$w_{i}$ - waga i-tego modułu<br>\n",
    "$m_{i}(t)$ - liczb wyrazów dopasowanych przez i-ty moduł<br>\n",
    "$|t|$ - liczba wszystkich wyrazów w tłumaczeniu<br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(t) + w_{stem} * m_{stem}(t) + w_{synonym} * m_{synonym}(t) + w_{paraphrase} * m_{paraphrase}(t) }{6}\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$\n",
    "* Pokrycie <br>\n",
    "Stosunek wyrazów w tłumaczeniu wzorcowym, które zostały dopasowane w tłumaczeniu maszynowym do wszystkich wyrazów tłumaczenia wzorcowego.\n",
    "$$\n",
    "  R = \\frac{\\sum \\limits_{i=1} ^{n} w_{i} * m_{i}(r)}{|r|}\n",
    "$$\n",
    "$m_{i}(r)$ - liczba wyrazów dopasowanych w tłumaczeniu referencyjnym<br>\n",
    "$|r|$ - liczba wyrazów tłumaczenia wzorcowego <br>\n",
    "\n",
    "Przykład:\n",
    "$$\n",
    "  P = \\frac{w_{exact} * m_{exact}(r) + w_{stem} * m_{stem}(r) + w_{synonym} * m_{synonym}(r) + w_{paraphrase} * m_{paraphrase}(r) }{6}\n",
    "$$\n",
    "$$\n",
    "  P = \\frac{w_{exact} * 1 + w_{stem} * 1 + w_{synonym} * 1 + w_{paraphrase} * 2 }{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26961d6-34fe-4333-ba38-ef912ad7a34f",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "W przeciwieństwiem do BLEU, METEOR korzysta nie tylko z miary precyzji (Precision), ale również Recall, która została potwierdzona przez inne metryki jako znacząca dla korelacji z ludzkim osądem. METEOR rozwiązuje również problem różnorodności tłumaczeń referencyjnych wykorzystując bardziej elastyczne dopasowanie słów, co pozwala na dopasowanie odpowiedników dla danych wariantów. Dodatkowo, składniki metryki METOR są sparametryzowane. Daje to możliwość dopasowania optymalnych parametrów dla danego języka, który może przywiązywać inną wartość do różnych części zdania.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7fa80-6bd9-4b71-8cdf-2b35a8337716",
   "metadata": {},
   "source": [
    "<a id =\"METEOR_P\"></a>\n",
    "<b>Problemy metryki METEOR</b>\n",
    "\n",
    "Wiele problemów metryki BLEU rozwiązuje metryka METEOR, więc można powiedzieć, że udaje jej się osiągnąć swój cel. Niemniej jednak istnieją pewne wady tej metryki:\n",
    "* Dużo większe skomplikowanie liczenia metryki\n",
    "* Jakość tłumaczenia zależy od baz danych, które zostają użyte do ewaluacji - im lepsza baza danych, tym bardziej zaufana wartość metryki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f4f57-3a14-49db-b963-f1f21c2ade4e",
   "metadata": {},
   "source": [
    "### ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41d677-6e05-428c-a472-c539945498b9",
   "metadata": {},
   "source": [
    "**<font color='red'>R</font>ecall-<font color='red'>O</font>riented <font color='red'>U</font>nderstudy for <font color='red'>G</font>isting <font color='red'>E</font>valuation**\n",
    "<a id =\"ROGUE_O\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055aa707-fbee-44ac-9300-3696109d8d69",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "ROUGE to zbiór metryk używanych do oceny automatycznego streszczania plików i tłumaczenia maszynowego. Jest to bardzo prosta teoretycznie metryka posługująca się podczas swojego działania miarami: \"Recall\", \"Precision\" i \"F1 Score\". \n",
    "</p>\n",
    "\n",
    "Niemniej jednak, istnieje kilka różnych odmian metryki ROUGE:\n",
    "\n",
    "* ROUGE-N: Analizuje wystąpujące n-gramy pomiędzy danymi referencyjnymi i ocenianym modelem\n",
    "* ROUGE-L: Posługuje się najdłuższym wspólnym podciągiem pomiędzy danymi referencyjnymi i wzorcem\n",
    "* ROUGE-W: Posługuje się najdłuższym wspólnym podciągiem i wagami.\n",
    "\n",
    "Do najważniejszych z nich należy ROUGE-N i ROUGE-L."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3ec72-e2bf-4b12-b1b1-9da00b241d46",
   "metadata": {},
   "source": [
    "<b> ROUGE-N </b> </br>\n",
    "<a id =\"ROUGE_N\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "Jest to jedna z podstawowych metryk zbioru metryk ROUGE. W swoim działaniu opiera się na mierzeniu licbzy pasujących n-gramu pomiedzy modelem (kandydatem), a danymi referencyjnymi (wzorcem). ROUGE-N może być rozpatrywany dla różnej, naturalnej wartości N. Jednakże, ROUGE-1, ROUGE-2 i ROUGE-3 to najczęściej spotykane szczególne przypadki metryki ROUGE-N. W praktyce oznacza to metryki ROUGE-N zorientowane kolejno na unigramach, bigramach i trigramach.\n",
    "</p>\n",
    "<b> Działanie: </b> </br>\n",
    "<a id =\"ROUGE_N_D\"></a>\n",
    "Metryka ROUGE-N posługuje się podczas działania miarami \"Recall\", \"Precison\" i \"F1 Score\" definiując ich wartości następująco:\n",
    "\n",
    "<h5>Recall</h5>\n",
    "<p style='text-align: justify;'>\n",
    "Miara Recall to stosunek liczby wspólnych n-gramów występujących pomiędzy wzorcem i kandydatem do liczby wszystkich n-gramów we wzorcu. Miara ta jest najczęściej liczona w oparciu o różne wartości naturalne n. \n",
    "</p>\n",
    "Przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82b33aa-2065-4b10-8631-092408d9b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozpatrywany N-gram\n",
    "ngram = 1\n",
    "\n",
    "# Tłumaczenie referencyjne\n",
    "reference = 'the fox jumps'\n",
    "reference = reference.split()\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'the hello a cat dog fox jumps'\n",
    "candidate = candidate.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78d13004-224b-4608-b541-eb2c3361f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.ROUGE_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f380fdb9-ad02-49a6-9c53-2dc684f39d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)  the                 \t\t\t\t1\n",
      "2)  fox                 \t\t\t\t1\n",
      "3)  jumps               \t\t\t\t1\n",
      "Miara recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Miara recall: \", calculateRecall(ngram, reference, candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d83f0-d961-4e45-bd7e-08ebda620769",
   "metadata": {},
   "source": [
    "<h5>Precision</h5>\n",
    "<p style='text-align: justify;'>\n",
    "Miare Precision jest miarą pozbawioną poważnej wady miary Recall, której wartość można zaburzyć poprzez wstawienie w miejsce modelu całego zbioru n-gramów. Takie podejście zagwarantuje, że każdy n-gram zostanie odnaleziony, a miara Recall zawsze będzie wynosić 1. W celu naprawy tego problemu Precision jest stosunekiem liczby wspólnych n-gramów występujących pomiędzy wzorcem i kandydatem do liczby n-gramów w kandydacie. Taka zmiana gwarantuje, że próba oszukania miary poprzez wstawienie wszystkich możliwości do badanego modelu spowoduje bardzo niskie wartości miary.\n",
    "</p>\n",
    "Przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2d2eda38-908f-4e38-b7a2-a40bb158d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyrażenia regularne do wyszukiwania słów w tekście:\n",
    "import re\n",
    "\n",
    "# Rozpatrywany N-gram\n",
    "ngram = 1\n",
    "\n",
    "# Tłumaczenie referencyjne\n",
    "reference = 'the fox jumps'.split()\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'the hello a cat dog fox jumps'\n",
    "candidate = candidate.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "afbf3993-6e1e-40aa-a531-4ff5d7f21265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definiuje liczbę rozpatrywanych n-gramów zależnie od przypisanych wag\n",
    "def getNumberOfnGram(weights):\n",
    "    n = len(weights)\n",
    "    result = 0\n",
    "    for i in range(1, n):\n",
    "        if( weights[i - 1] == 0 ):\n",
    "            break\n",
    "        else:\n",
    "            result = i\n",
    "    return result + 1\n",
    "\n",
    "# Zwraca liczbę wystąpień pattern w text - wyrażenia regularne\n",
    "def getNumberOfOccurance(pattern, text):\n",
    "    # \"pattern\"\n",
    "    number = re.findall(\"^\" + pattern + \"$\", text)\n",
    "    # \"pattern \"\n",
    "    number = number + re.findall(\"^\" + pattern + \" \", text)\n",
    "    # \" pattern \"\n",
    "    number = number + re.findall(\" \" + pattern + \" \", text)\n",
    "    # \" pattern\"\n",
    "    number = number + re.findall(\" \" + pattern + \"$\", text)\n",
    "    if(len(number) > 0):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Tworzy z inputList listę bez duplikatów\n",
    "def makeUniqueList(inputList):\n",
    "    unique_list = []\n",
    "    for element in inputList:\n",
    "        if element not in unique_list:\n",
    "            unique_list.append(element)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2b5e83ef-99aa-4df9-898d-db0c2b2a5324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)  the                 \t\t\t\t1\n",
      "2)  fox                 \t\t\t\t1\n",
      "3)  jumps               \t\t\t\t1\n",
      "Miara recall:  0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# Zmienne pomocnicze\n",
    "unique_reference = makeUniqueList(reference)\n",
    "tabs = '\\t\\t\\t\\t'\n",
    "sumOfGram = 0\n",
    "\n",
    "# Liczba n-gramów:\n",
    "if(ngram > 1):\n",
    "    unique_reference = reference\n",
    "nmbOfGrams = len(unique_reference) - ngram + 1\n",
    "counter = 1\n",
    "    \n",
    "# Pętla po liczbie n-gramów zależna od rozpatrywanego n-gramu\n",
    "for idOfPattern in range(0, nmbOfGrams):\n",
    "        \n",
    "    gram = unique_reference[idOfPattern]\n",
    "        \n",
    "    # Pętla po liczbie słów do dodania aby otrzymać n-gram\n",
    "    for idToAdd in range(1, ngram):\n",
    "        gram = gram + ' ' + unique_reference[idOfPattern + idToAdd]\n",
    "        \n",
    "    #Wypisanie początku wiersza tabeli\n",
    "    print(\"{0:<4}\".format(str(counter)+ \")\"), end='')\n",
    "    print(\"{0:<20}\".format(gram), end='')\n",
    "    print(tabs, end='')\n",
    "        \n",
    "    #Zmienne dla konkretnego n-gramu:\n",
    "    counter = counter + 1\n",
    "    candidateWithSpace = ' '.join(map(str, candidate))\n",
    "        \n",
    "    # Sprawdzenie wystąpienia konkretnego n-gramu w referencji\n",
    "    gramOccurrances = getNumberOfOccurance(gram, candidateWithSpace)\n",
    "    sumOfGram = sumOfGram + gramOccurrances\n",
    "    print(str(gramOccurrances))\n",
    "        \n",
    "precision = sumOfGram/(len(makeUniqueList(candidate)) - ngram + 1)\n",
    "\n",
    "print(\"Miara precision: \", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa1432-cd14-4f50-99d0-1c77311ed277",
   "metadata": {},
   "source": [
    "<h5>F1 Score</h5>\n",
    "<p style='text-align: justify;'>\n",
    "Miara F1 Score jest połączenie miary \"Recall\" i \"Precision\" zgodnie ze wzorem:\n",
    "\n",
    "$$\n",
    "F1_{Score} = 2 * \\frac{precision * recall}{precision + recall}\n",
    "$$\n",
    "Wartość miary F1 daje nam wiarygodną informacje o jakości naszego modelu, która jest uzależniona nie tylko od skuteczności naszego modelu, która można zawyżyć używając wszystkich przypadków (recall), ale uwzględnia również nieistone n-gramy.\n",
    "</p>\n",
    "Przykładowo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70ffa20d-9ba9-4765-b1c5-dd490b5c44d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miara F1:  0.6\n"
     ]
    }
   ],
   "source": [
    "F1 = 2 * (recall * precision)/(precision + recall)\n",
    "print(\"Miara F1: \", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d171a-2e04-447f-b769-6ffd728f224d",
   "metadata": {},
   "source": [
    "<b> ROUGE-L </b> </br>\n",
    "<a id =\"ROUGE_L\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "Jest to również jedna z bazowych metryk ROUGE. Jej działanie opiera się na najdłuższym wspólnym podciągu znalezionym pomiedzy modelem i referencją. Najdłuższy wspólny podciąg jest rozumiany jako najdłuższy podciąg znaków, który występuje w tej samej kolejności w dwóch porównywalnych łańcuchach znaków. Elementy podciągów nie muszą przy tym leżeć obok siebie.\n",
    "</p>\n",
    "<b> Działanie: </b> </br>\n",
    "<a id =\"ROUGE_L_D\"></a>\n",
    "<p style='text-align: justify;'>\n",
    "ROUGE-L posługuje się najdłuższym wspólnym podciągiem obu wyrazów, ale w operując na poziomie całych słów. Długość NWP oznacza ilość pełnych słów w danym znalezionym podciągu, a nie, jak standardowo, ilość znaków w podciągu.\n",
    "</p>\n",
    "<h5>Najdłuższy wspólny podciąg na poziomie słów:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae853c8-9aa4-4521-adba-a0913e43cc70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wyrażenia regularne do wyszukiwania słów w tekście:\n",
    "import re\n",
    "\n",
    "# Rozpatrywany N-gram\n",
    "ngram = 1\n",
    "\n",
    "# Tłumaczenie referencyjne\n",
    "reference = 'the fox jumps'.split()\n",
    "\n",
    "# Tłumaczenie kandydujące\n",
    "candidate = 'the hello a cat dog fox jumps'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949e7a0e-ddfb-4dbb-96ef-bf7f3be31ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funkcja zwracająca długość najdłuższego wspólnego podłańcucha\n",
    "def longestCommonSubsequence(text1 , text2):\n",
    "    m = len(text1)\n",
    "    n = len(text2)\n",
    "    matrix = [[0]*(n+1) for i in range(m+1)] \n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i==0 or j==0:\n",
    "                matrix[i][j] = 0\n",
    "            elif text1[i-1] == text2[j-1]:\n",
    "                matrix[i][j] = 1 + matrix[i-1][j-1]\n",
    "            else:\n",
    "                matrix[i][j] = max(matrix[i-1][j] , matrix[i][j-1])\n",
    "    return matrix[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a160c89e-fbca-4ec3-80e0-b4170fee4ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Długość najdłuższego wspólnego podłańcucha:  3\n"
     ]
    }
   ],
   "source": [
    "length = longestCommonSubsequence(candidate, reference)\n",
    "print(\"Długość najdłuższego wspólnego podłańcucha: \", length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159132cb-62b9-44c0-977d-b49d64d7c1e4",
   "metadata": {},
   "source": [
    "Kolejnym krokiem po znalezieniu NWP jest obliczenie wartości metryki ROUGE-L zgodnie ze wzorami:\n",
    "$$\n",
    "Recall = \\frac{l}{n}\n",
    "$$\n",
    "$l$ - długość NWP <br>\n",
    "$n$ - ilość unigramów w referencji <br>\n",
    "\n",
    "$$\n",
    "Precision = \\frac{l}{m}\n",
    "$$\n",
    "$l$ - długość NWP <br>\n",
    "$m$ - ilość unigramów w kandydacie <br>\n",
    "\n",
    "$$\n",
    "F1_{Score} = 2 * \\frac{precision * recall}{precision + recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52e71a9-1eaa-4eaf-bced-622d20a8ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.0\n",
      "Precision: 0.42857142857142855\n",
      "F1 Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "recall = length/len(reference)\n",
    "print(\"Recall: \" + str(recall))\n",
    "precision = length/len(candidate)\n",
    "print(\"Precision: \" + str(precision))\n",
    "f1 = 2 * (recall * precision)/(precision + recall)\n",
    "print(\"F1 Score: \" + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667cb89-fed1-4e32-9294-e96c1d22bdd9",
   "metadata": {},
   "source": [
    "<a id =\"ROUGE_P\"></a>\n",
    "<b> Problemy metryki ROUGE </b>\n",
    "<br>\n",
    "Metryka ROUGE jest bardzo często używana, jednakże nie jest pozbawiona pewnych wad. Wśród nich wymienia się:\n",
    "* metryka nie analizuje podobieństwa różnych słów o tym samym znaczeniu - mierzy dopasowania syntaktyczne, a nie semantykę. Dwa zdania o tym samym znaczeniu zapisane za pomocą różnych słów mogą mieć zaniżoną wartość metryki ze względu na użycie synonimów.\n",
    "* metryka ROUGE nie znajduje zastosowania do ewaluacji streszczeń, ponieważ częstym zabiegiem w takich procesach jest zastępowanie dłuższych zwrotów krótszymi synonimami, które metryka ROUGE uzna za błąd. Ponadto metryka ta nie ocenia czytelności i płynności generowanych podsumowań.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0df95-1cca-45fc-9ada-ee8dc58d6262",
   "metadata": {},
   "source": [
    "<b>Python Rouge Library</b>\n",
    "<br>\n",
    "\"Python rouge library\" jest dodatkową biblioteką umożliwiająca liczenie wartości metryki ROUGE. Domyślnie wynik jest podawamy dla ROUGE-1, ROUGE-2 i ROUGE-L z podziałem na wartość:\n",
    "* \"r\" - Recall, \n",
    "* \"p\" - Precision, \n",
    "* \"f\" - \"F1 Score\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "618dab47-b6dc-4f86-b717-917e5049ddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 1.0, 'p': 0.42857142857142855, 'f': 0.5999999958},\n",
       "  'rouge-2': {'r': 0.5, 'p': 0.16666666666666666, 'f': 0.24999999625000005},\n",
       "  'rouge-l': {'r': 1.0, 'p': 0.42857142857142855, 'f': 0.5999999958}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "candidate = \"the hello a cat dog fox jumps\"\n",
    "\n",
    "reference = \"the fox jumps\"\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge.get_scores(candidate, reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b71d2-404c-4e6e-ac93-e90e1919b939",
   "metadata": {},
   "source": [
    "### WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361a0e3-7b62-4378-bc57-687997f1fa70",
   "metadata": {},
   "source": [
    "**<font color='red'>W</font>ord <font color='red'>M</font>over's <font color='red'>D</font>instance**\n",
    "<a id =\"WMD_O\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04010-1052-4a84-b5a7-f4ad9a31b575",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "WMD to relatywnie nowe narzędzie funkcjonujące w oparciu o uczenie maszynowe używane jako metryka jakości podobieństwa dwóch dokumnetów. Najważniejszą cechą metryki WMD jest możliwość oceny dwóch tekstów o podobnym znaczeniu, ale używających różnych słów do wyrażenia tej samej idei. \n",
    "</p>\n",
    "\n",
    "<b> Działanie: </b> </br>\n",
    "<a id =\"WMD_D\"></a>\n",
    "Celem WMD jest zmierzenie odległości semantycznej dwóch tekstów, która jest szacowana z uwzględnieniem możliwości występowania synonimów. Typowym przykładem przy omawianiu metryki WMD są zdania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eabd6e-beed-4939-9abb-cf99fdd75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zdanie 1\n",
    "reference = 'Obama speaks to the media in Illinois'.split()\n",
    "\n",
    "# Zdanie 2\n",
    "candidate = 'The president greets the press in Chicago'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34288cc8-78e3-4646-8694-dd3f2c1ecc64",
   "metadata": {},
   "source": [
    "Oba zdania wyrażają bardzo podobną myśl przy użyciu całkowicie odmiennych słów. Spodziewana wartość metryki w takiej sytuacji jest dość wysoka.\n",
    "<p align=\"center\">\n",
    "  <img src=\"WMD_schemat.png\"/>\n",
    "</p>\n",
    "Powyższe zdjęcie przedstawia wizualizacje tych dwóch zdań stosująć wektorową reprezentację dokumentów \"word2vec\". Zasada jej działania polega na minimalizacji dystanu pomiędzy słowami, które często występują w swoim otoczeniu. Przykładowo słowo \"kwiatek\" i \"łąka\" powinny być bliżej siebie niż \"kwiatek\" i \"pustynia\".\n",
    "<br>\n",
    "\n",
    "Analiza omawianego przykładu zaczyna się od usunięcia tzw. \"przerywników\", które niepotrzebnie zwiększają złożoność algorytmu i prowadzą do błędów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1cd4b6-f54f-4cf5-9452-1bfedd2d409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zdanie 1 po usunięciu przerywników:  president greets press chicago\n",
      "Zdanie 2 po usunięciu przerywników:  obama speaks media illinois\n"
     ]
    }
   ],
   "source": [
    "# Usunięcie wielkich liter i podział na listy słów\n",
    "reference = [w.lower() for w in reference]\n",
    "candidate = [w.lower() for w in candidate]\n",
    "\n",
    "# Pobranie zbioru \"przerywników\" dla języka angielskiego\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "# Usunięcie przerywników\n",
    "reference = [w for w in reference if w not in stopWords]\n",
    "candidate = [w for w in candidate if w not in stopWords]\n",
    "\n",
    "print(\"Zdanie 1 po usunięciu przerywników: \", ' '.join(map(str, candidate)))\n",
    "print(\"Zdanie 2 po usunięciu przerywników: \", ' '.join(map(str, reference)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49872e98-766c-433b-ac7e-7a2d3271980b",
   "metadata": {},
   "source": [
    "Następnie dla skróconych zdań jest liczony koszt zmiany każdego słowa pierwszego zdania na każdego słowo drugiego zdania i wybierany jest minimalny koszt. Jest to krok konieczny, ponieważ algorytm nie wie, że przykładowo najmniejszym kosztem będzie charakteryzować się zamiana \"obama\" na \"president\", ponieważ oba słowa często występują w swoim otoczeniu. Wynikiem metryki jest najmniejszy znaleziony dystans pomiędzy zdaniami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3a5c1-06c7-4949-918b-1123c2b4c987",
   "metadata": {},
   "source": [
    "<a id =\"WMD_P\"></a>\n",
    "<b> Problemy metryki WMD </b>\n",
    "<br>\n",
    "Metryka WMD pomimo dość niedawnego powstania zmaga się z pewnymi problemami:\n",
    "* Wartość metryki zależy od jakości baz danych użytych do ewaluacji. \n",
    "* Relatywnie skomplikowany proces liczenia, co przekłada się na długi czas oczekiwania na wartość metryki.\n",
    "* Złożoność obliczeniowa $O(p^3log(p))$ w podstawowej wersji, gdzie p to liczba unikatowych słów\n",
    "* Porównanie dokumentów, w których występują wspólne słowa występujące w innym kontekście może utrudnić porównanie - problem polisemii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0dea50-0fd3-40e0-a529-294161082c37",
   "metadata": {},
   "source": [
    "<a id =\"CIDER\"></a>\n",
    "### CIDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611113f-1fd7-498a-bb3b-9b8e29c7b8c8",
   "metadata": {},
   "source": [
    "**<font color='red'>C</font>onsensus-based <font color='red'>I</font>mage <font color='red'>D</font>escription <font color='red'>E</font>valuation**\n",
    "\n",
    "<a id =\"CIDER_O\"></a>\n",
    "<a id =\"CIDER_D\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6ab3f-636c-4f6c-9911-6524539ac7ef",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Metryka CIDEr mierzy zgodność pomiędzy opisami dwóch obrazów w oparciu o metodę TF-IDF (ważenie częstością termów -metoda pozwalająca na obliczenie wagi słów w oparciu o liczbę wystąpień) liczoną dla każdego n-gramu. Liczba wystąpień n-gramu $w_k$ w zdaniu referencyjnym $s_{ij}$ jest oznaczona przez $h_{k}(s_{ij})$ lub $h_{k}(c_{i})$ dla zdania ocenianego (kandydującego) $c_i$. Metryka CIDEr przelicza wartość wagi TF-IDF $g_{k}(s_{ij})$ dla każdego n-gram $w_{k}$ zgodnie ze wzorem:\n",
    "</p>\n",
    "$$\n",
    "g_{k}(s_{ij}) = \\frac{h_{k}(s_{ij})}{\\sum \\limits_{w_l \\in \\Omega} h_{l}(s_{ij})} log \\Biggl( \\frac{|I|} {\\sum \\limits_{I_p \\in I} min(1, \\sum \\limits_{q} h_k(s_{ij}))} \\Biggr)\n",
    "$$\n",
    "gdzie: \n",
    "<br>\n",
    "$ \\Omega $ - słownictwo związane z każdym n-gramem <br>\n",
    "$ I $ - zbiór wszystkich obrazów w zbiorze danych\n",
    "<p style='text-align: justify;'>\n",
    "Pierwsza część odpowiada za mierzenie TF każdego n-gramu $w_k$, a druga część mierzy rzadkość $w_k$ używając IDF. Zgodnie z intuicją TF przypisuje większą wagę do n-gramów, które często wystąpują w zdaniach referencyjnych opisujących obraz, a jednocześnie IDF zmniejsza wage n-gramów, które często występują we wszystkich opisach. W konsekwencji IDF odpowiada za zapewnienie zachowania istotności wyrazów poprzez zaniżanie wartości częstych słów, które mają małe prawdopodobieństwo na przechowywania ważnych informacji o opisywanym obrazie. IDF jest obliczany jako logarytm liczby obrazów w zbiorze |I| przez liczbę obrazów, dla których $w_k$ występuje w dowolnym z jego zdań referencyjnych.\n",
    "\n",
    "Wartoś metryki CIDEr jest obliczona na podstawie wszystkich n-gramów o długości n używając średniego podobieństwa cosinusowego pomiędzy kandydatem i zdaniami referencyjnymi:\n",
    "    \n",
    "$$\n",
    "CIDEr_n(c_i, S_i) = \\frac{1}{m}{\\sum \\limits_{j} \\frac{g^n(c_i) g^n(s_{ij})}{|g^n(c_i)||g^n(s_{ij})|}}\n",
    "$$\n",
    "gdzie: \n",
    "<br>\n",
    "$ g^n(c_i) $ - wektor wartości $ g_k(c_i)$ odpowiadający wszystkim n-gramom długości n <br>\n",
    "$ |g^n(c_i)| $ - rozmiar wektora $ g^n(c_i) $ <br>\n",
    "    \n",
    "Wyższe n-gramy (dla większego n) są używane do uchwycenia gramatycznych cech i bogatszej semantyki. Wyniki różnych n-gramów są ujednolicane zgodnie ze wzorem:\n",
    "<br>\n",
    "$$\n",
    "CIDEr(c_i, S_i) = {\\sum \\limits_{n=1} ^{N} w_n CIDEr_n(c_i, S_i)}\n",
    "$$\n",
    "    \n",
    "Najczęściej używa się $ w_n = \\frac{1}{N}$ i $ N=4 $\n",
    "    \n",
    "<a id =\"CIDER_D_D\"></a>\n",
    "<b> CIDEr-D </b>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "CIDEr-D jest modyfikacją podstawowej wersji metryki CIDEr-D, której celem jest przeciwstawienie się problemowi tworzenia zdań, które poprzez znajomość sposobu liczenia metryki są wysoko oceniane przez CIDEr jednocześnie będąc niezgodne z ludzkim osądem. Jest to problem, który dotyczy wszystkich metryk. W celu zapobiegania temu zjawisko CIDEr-D stosuje kary dla oceny za różnice w długościach opartą o wartości krzywej Gaussa. Jest to mechanizm zapobiegający w dużym stopniu sztucznemu zawyżeniu oceny CIDEr.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd624d6-49b0-4f89-82f5-f3a9f8d4f4bd",
   "metadata": {},
   "source": [
    "### Wartości Shapleya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870550a-e5c3-42fa-a9d2-ce0eb67cf26f",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Teoretycznie każde zjawisko wystąpujące w świecie można zamodelować matematycznie. Szczególnym typem zjawisk związanych z wartościami Shapleya są takie, które w zależności od przyjętej kombinacji podmiotów biorących udział w danym zdarzeniu można odnieść różne korzyści. Przykładowo w zależności od wystawionej kadry piłkarkiej można uzyskać różny wynik meczu. W takim przypadku pojawia się również problem jak dany podmiot wpłynął na ostateczny wynik. Rozwiązaniem tego dylematu zajął się Lloyda Shapley w 1953 roku, który wprowadził pojęcie tzw. \"wartości Shapleya\".\n",
    "</p>\n",
    "<b>Teoria</b>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "Sytuacji opisana powyżej jest modelowana poprzez grę koalicyjną, w której biorze udział zbiór graczy $N$ oraz funkcję, która przyporządkowuje każdemu podzbiorowi graczy liczbę stanowiącą wartość danego zespołu (funkcja koalicyjna/charakterystyczna):\n",
    "$$\n",
    "v: 2^N -> \\mathbb{R}.\n",
    "$$\n",
    "Cechą gier koalicyjnych jest również syperaddytywność, która oznacza, że większa korzyść jest osiągalna przez łączenie się graczy w kolacji.Prowadzi do to następującego wniosku: największa korzyść jest osiągalna przez zaangażowanie wszystkich graczy (wielka kolicja). W takim przypadku wkład każdego gracza w kolację $S$ można obliczyć korzystając z wartości Shapleya dla danego gracza $i$. Niemniej jednak, żeby ją policzyć niezbędne jest uzyskanie wartości \"wkładu marginalnego\" danego gracza $i$ w kolację $S$ oznaczoną wartością: $v(S \\cup \\{i\\}) - v(S)$. Wtedy wartość Shapleya dla gracza $i$ przyjmuje postać:\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "{\\sum \\limits_{S \\in N -\\{ i\\}} \\frac{|S|!(n-|S|-1)!}{n!} (v(S\\cup i) - v(S))} \n",
    "$$\n",
    "W praktyce oznacza to, że uśrednia się wkład marginalny danego gracza i, licząc po wszystkich kolacjach, które nie zawierają danego gracza, z uwzględnieniem kolejności dołączania graczy do kolacji.\n",
    "</p>\n",
    "<b>Wartości Shapleya w ML</b>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "W podstawowym modelu uczenia maszynowego gracze gry kooperacyjnej mogą zostać zastąpieni cechami modelu, a ostatecznym wynik poprzez sam wynik końcowy modelu. Jednakże proces liczenia wartości Shapleya dla danego atrybutu niezawsze jest możliwy do przeprowadzenia ze względu na brak możliwości wykluczenia danego atrybutu. W konsekwencji wykluczenie atrybutu w przypadku uczenia maszynowego jest symulowane poprzez próbkowanie empirycznego rozkładu wartości cech i uśrednianie próbek. Proces ten może być kosztowny obliczeniowo, dlatego większość metod obliczania wartości Shapleya dla modelu uczenia maszynowego generuje oszacowania prawdziwej wartości Shapleya. Algorytmami zajmującymi się tym procesem są stosunkowo nowe algorytmy SHAP i QII.\n",
    "<br>\n",
    "<b>Ograniczenia wartości Shapleya w ML</b>\n",
    "</p>\n",
    "\n",
    "* Obliczanie wartości Shapleya wymaga selekcji koalicji i podzbiorów atrybutów, których liczba rośnie ekspotencjalnie. W konsekwencji policzenie wartości Shapleya dla naprawdę dużych zbiór jest praktycznie niemożliwe. Problem ten jest rozwiązywany poprzez techniki aproksymacyjne i korzystanie ze szczególnych cech charakterystycznych dla danego modelu.\n",
    "* Liczenie wartości Shapleya uwzględnia również koalicje, które są nierealne dla rozpatrywanego modelu. Przykładowo rozważając model, który dla danych atrybutów mieszkania przewiduje jego cenę, można sobie wyobrazić sytuację rozpatrywania mieszkania w centrum miasta z wiodkiem na morze. W takiej sytuacji rozpatrywanie wartości Shapleya nie ma większego szensu, ponieważ wyniki te są zaburzone poprzez nierealne dane.\n",
    "    \n",
    "    \n",
    "Warto zauważyć, że liczenie wartości Shapleya wymaga jedynie dostępu do wyniku wartości modelu uczenia dla konkretnych danych wejściowych bez znajomości konkretnej mechaniki modelu. W konsekwencji jest to technika niezależna od modelu.\n",
    "\n",
    "\n",
    "<b>Przykład</b>\n",
    "<br>\n",
    "<p style='text-align: justify;'>\n",
    "Rozważmy sytuację, w której występuje n graczy w postaci liczb naturalnych. Funkcja koalicyjna przyporządkowuje sumę kwadratów graczy, którzy wzięli udział w rozważanej grze koalicyjnej. Problem jest wskazanie wpływu każdego z graczy na wynik.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564876eb-bea8-4f99-a768-6c5859064a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABELA DLA: 3\n",
      "Nr:\t Kombinacja:\t\t\tBez gracza:\t\tZ graczem:\t\tWkład marginalny:\tSkalowany wkład marginalny:\n",
      "1)       []                             0                       9                       9                       2.25                \n",
      "2)       [4]                            16                      49                      33                      2.75                \n",
      "3)       [2]                            4                       25                      21                      1.75                \n",
      "4)       [1]                            1                       16                      15                      1.25                \n",
      "5)       [2, 4]                         36                      81                      45                      3.75                \n",
      "6)       [1, 4]                         25                      64                      39                      3.25                \n",
      "7)       [1, 2]                         9                       36                      27                      2.25                \n",
      "8)       [1, 2, 4]                      49                      100                     51                      12.75               \n",
      "\n",
      "Wartość Shapleya dla 3: 30.0\n",
      "Wkład procentowy: 30.000%\n"
     ]
    }
   ],
   "source": [
    "from functions.SHAPLEY_functions import *\n",
    "# Gracze\n",
    "players = [1, 2, 3, 4]\n",
    "player = 3\n",
    "\n",
    "shapley(players, player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b3ab4-a024-4a1c-a648-523efad5a3aa",
   "metadata": {},
   "source": [
    "<b>Przykład</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bab4f-3977-4e1f-86f1-8e1e03b89632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ff8acf-a6b6-4314-a1ba-ab6962438672",
   "metadata": {},
   "source": [
    "<a id =\"SOURCE\"></a>\n",
    "### Źródła\n",
    "BLEU:\n",
    "* https://towardsdatascience.com/bleu-bilingual-evaluation-understudy-2b4eab9bcfd1\n",
    "* https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b\n",
    "* http://docplayer.pl/14218168-Ewaluacja-systemow-tlumaczenia-automatycznego.html\n",
    "</br>\n",
    "\n",
    "METEOR:\n",
    "* http://docplayer.pl/14218168-Ewaluacja-systemow-tlumaczenia-automatycznego.html\n",
    "* https://www.jstor.org/stable/40783462\n",
    "</br>\n",
    "\n",
    "ROUGE:\n",
    "* https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
    "* https://en.wikipedia.org/wiki/Automatic_summarization\n",
    "* https://en.wikipedia.org/wiki/ROUGE_(metric)\n",
    "* https://pl.wikipedia.org/wiki/Najdłuższy_wspólny_podciąg\n",
    "* https://towardsdatascience.com/to-rouge-or-not-to-rouge-6a5f3552ea45\n",
    "* https://ryanong.co.uk/2020/01/23/day-18-summarisation-evaluation-metrics/\n",
    "\n",
    "WMD:\n",
    "* https://towardsdatascience.com/word-distance-between-word-embeddings-cc3e9cf1d632\n",
    "* https://ermlab.com/blog/technicznie/doc2vec-wektorowa-reprezentacja-dokumentow/\n",
    "* https://medium.com/@nihitextra/word-movers-distance-for-text-similarity-7492aeca71b0\n",
    "* https://towardsai.net/p/nlp/word-movers-distance-wmd-explained-an-effective-method-of-document-classification-89cb258401f4\n",
    "* https://www.youtube.com/watch?v=nX1g_wPSYOI\n",
    "\n",
    "CIDEr:\n",
    "* https://arxiv.org/pdf/1504.00325.pdf\n",
    "* https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf\n",
    "\n",
    "Wartości Shapleya:\n",
    "* https://towardsdatascience.com/the-shapley-value-for-ml-models-f1100bff78d1\n",
    "* https://christophm.github.io/interpretable-ml-book/shapley.html\n",
    "* https://pl.wikipedia.org/wiki/Wartość_Shapleya\n",
    "* https://towarzystwo.edu.pl/assets/prace_matematyczne/Dmigacz.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df09b9e-e4af-421b-97c2-8cc868c3e353",
   "metadata": {},
   "source": [
    "<b> To-do: </b>\n",
    "* Dodać coco-caption\n",
    "* Dodać liczenie WMD\n",
    "* Dodać drugi przykład w wartościach Shapleya\n",
    "* Zredagować całość\n",
    "* Przenieść kod metryki ROUGE do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af34338-9842-4557-bc72-eb25bf998fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
